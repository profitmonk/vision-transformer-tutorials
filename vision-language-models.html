<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Vision-Language Models: GPT-4V, Gemini, Claude</title>
  <style>
    body{font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,sans-serif;max-width:1200px;margin:0 auto;padding:20px;background:linear-gradient(135deg,#1a1a1a 0%,#2d2d2d 100%);color:#e0e0e0;line-height:1.6}
    .container{background:#fff;color:#2d2d2d;border-radius:20px;padding:30px;margin:20px 0;border:1px solid #e0e0e0;box-shadow:0 4px 20px rgba(0,0,0,.1)}
    .nav-bar{background:#2d2d2d;color:#fff;padding:15px 30px;border-radius:15px;margin:20px 0;display:flex;justify-content:space-between;align-items:center;flex-wrap:wrap;gap:15px}
    .nav-home,.nav-prev,.nav-next{background:#fff;color:#2d2d2d;padding:8px 16px;border-radius:6px;text-decoration:none;font-weight:bold;transition:all .3s}
    .nav-next{background:#28a745;color:#fff}
    .nav-home:hover,.nav-prev:hover,.nav-next:hover{transform:translateY(-2px);box-shadow:0 4px 12px rgba(0,0,0,.2)}
    .nav-title{font-size:1.2em;font-weight:bold;flex:1;min-width:300px}
    .step{background:#f8f9fa;border:1px solid #e9ecef;padding:20px;margin:15px 0;border-radius:15px;border-left:4px solid #2d2d2d}
    .interactive-demo{background:#f8f9fa;border:2px solid #e9ecef;border-radius:15px;padding:25px;margin:20px 0}
    .demo-title{font-size:1.3em;font-weight:bold;margin-bottom:20px;text-align:center;color:#2d2d2d}
    .controls{display:grid;grid-template-columns:repeat(auto-fit,minmax(200px,1fr));gap:15px;margin:20px 0}
    .control-group{display:flex;flex-direction:column;gap:5px}
    .control-group label{font-weight:bold;font-size:14px;color:#2d2d2d}
    button{background:#2d2d2d;border:none;color:#fff;padding:12px 24px;border-radius:8px;cursor:pointer;font-weight:bold;transition:all .3s;margin:5px}
    button:hover{background:#1a1a1a;transform:translateY(-2px);box-shadow:0 4px 12px rgba(0,0,0,.2)}
    button.primary{background:#28a745}
    button.primary:hover{background:#218838}
    input,select,textarea{padding:8px 12px;border:1px solid #dadce0;border-radius:6px;background:#fff;color:#2d2d2d}
    textarea{min-height:70px;resize:vertical}
    .math-formula{background:#f8f9fa;border:1px solid #e9ecef;padding:20px;border-radius:8px;margin:15px 0;font-family:'Courier New',monospace;text-align:center;font-size:16px;box-shadow:0 2px 8px rgba(0,0,0,.1)}
    .code-block{background:#2d2d2d;color:#e0e0e0;padding:20px;border-radius:8px;margin:15px 0;font-family:'Courier New',monospace;font-size:14px;overflow:auto;position:relative}
    .code-header{background:#1a1a1a;color:#28a745;padding:8px 15px;margin:-20px -20px 15px -20px;border-radius:8px 8px 0 0;font-weight:bold;font-size:12px}
    .copy-button{position:absolute;top:10px;right:10px;background:#28a745;color:#fff;border:none;padding:4px 8px;border-radius:4px;cursor:pointer;font-size:10px}
    .architecture-flow{display:flex;justify-content:space-between;align-items:center;margin:20px 0;padding:20px;background:#fff;border-radius:12px;border:2px solid #e9ecef;flex-wrap:wrap;gap:15px}
    .arch-component{background:#f8f9fa;border:2px solid #e9ecef;border-radius:8px;padding:15px;text-align:center;min-width:120px;flex:1}
    .arch-component.vision{border-color:#dc3545}
    .arch-component.language{border-color:#007bff}
    .arch-component.fusion{border-color:#28a745}
    .arch-component.output{border-color:#ffc107}
    .arch-arrow{font-size:24px;color:#28a745;font-weight:bold}
    .model-comparison{display:grid;grid-template-columns:repeat(auto-fit,minmax(300px,1fr));gap:20px;margin:20px 0}
    .model-card{background:#fff;border:2px solid #e9ecef;border-radius:12px;padding:20px;transition:all .3s;cursor:pointer}
    .model-card:hover{border-color:#28a745;transform:translateY(-3px);box-shadow:0 6px 20px rgba(0,0,0,.1)}
    .model-card.selected{border-color:#28a745;background:#d4edda}
    .model-name{font-size:1.3em;font-weight:bold;margin-bottom:10px;color:#2d2d2d}
    .model-specs{background:#f8f9fa;padding:12px;border-radius:6px;margin:10px 0;font-size:12px;font-family:'Courier New',monospace}
    .model-capabilities{margin:15px 0}
    .capability{display:flex;align-items:center;margin:5px 0;font-size:14px}
    .capability-icon{margin-right:8px;font-size:16px}
    .token-flow{display:flex;flex-wrap:wrap;gap:8px;margin:15px 0;padding:15px;background:#f8f9fa;border-radius:8px}
    .token{padding:8px 12px;background:#e9ecef;border-radius:6px;font-family:'Courier New',monospace;font-size:12px;border:2px solid transparent}
    .token.text{border-color:#007bff;background:#cce7ff}
    .token.image{border-color:#dc3545;background:#ffcccc}
    .token.special{border-color:#28a745;background:#ccffcc}
    .attention-matrix{background:#fff;border:2px solid #e9ecef;border-radius:8px;padding:15px;margin:15px 0}
    .matrix-grid{display:grid;gap:2px;margin:10px 0}
    .matrix-cell{padding:6px;text-align:center;font-size:10px;border-radius:3px;font-weight:bold}
    .attention-high{background:#dc3545;color:#fff}
    .attention-medium{background:#ffc107;color:#000}
    .attention-low{background:#e9ecef;color:#495057}
    .metric-grid{display:grid;grid-template-columns:repeat(auto-fit,minmax(150px,1fr));gap:15px;margin:20px 0}
    .metric-card{background:#fff;border:2px solid #e9ecef;border-radius:8px;padding:15px;text-align:center}
    .metric-value{font-size:1.5em;font-weight:bold;color:#2d2d2d;margin-bottom:5px}
    .metric-label{font-size:12px;color:#666}
    .benchmark-table{width:100%;border-collapse:collapse;margin:15px 0;background:#fff;border:1px solid #e9ecef;border-radius:8px;overflow:hidden}
    .benchmark-table th{background:#2d2d2d;color:#fff;padding:12px;text-align:center;font-weight:bold}
    .benchmark-table td{padding:12px;text-align:center;border-bottom:1px solid #e9ecef}
    .score-excellent{background:#d4edda;color:#155724;font-weight:bold}
    .score-good{background:#d1ecf1;color:#0c5460;font-weight:bold}
    .score-average{background:#fff3cd;color:#856404;font-weight:bold}
    .score-poor{background:#f8d7da;color:#721c24;font-weight:bold}
    .conversation-demo{background:#fff;border:2px solid #e9ecef;border-radius:12px;padding:20px;margin:15px 0}
    .message{margin:10px 0;padding:15px;border-radius:8px;max-width:80%}
    .message.user{background:#e3f2fd;margin-left:auto;border-bottom-right-radius:4px}
    .message.assistant{background:#f3e5f5;margin-right:auto;border-bottom-left-radius:4px}
    .message.system{background:#fff3e0;margin:10px auto;text-align:center;font-style:italic;max-width:60%}
    .image-placeholder{width:200px;height:150px;background:linear-gradient(45deg,#e9ecef,#dee2e6);border-radius:8px;display:flex;align-items:center;justify-content:center;margin:10px 0;font-weight:bold;color:#495057}
    .fusion-strategies{display:grid;grid-template-columns:repeat(auto-fit,minmax(250px,1fr));gap:15px;margin:20px 0}
    .fusion-card{background:#fff;border:2px solid #e9ecef;border-radius:8px;padding:15px;cursor:pointer;transition:all .3s}
    .fusion-card:hover{border-color:#28a745;transform:translateY(-2px)}
    .fusion-card.selected{border-color:#28a745;background:#d4edda}
    .fusion-title{font-weight:bold;margin-bottom:8px;color:#2d2d2d}
    .fusion-description{font-size:13px;color:#666;margin-bottom:8px}
    .fusion-math{background:#f8f9fa;padding:8px;border-radius:4px;font-size:11px;font-family:'Courier New',monospace}
    .info{background:#d1ecf1;border-left:4px solid #17a2b8;color:#0c5460;padding:15px;border-radius:8px;margin:15px 0}
    .success{background:#d4edda;border-left:4px solid #28a745;color:#155724;padding:15px;border-radius:8px;margin:15px 0}
    .warning{background:#fff3cd;border-left:4px solid #ffc107;color:#856404;padding:15px;border-radius:8px;margin:15px 0}
    .breakthrough-highlight{background:linear-gradient(135deg,#28a745,#20c997);color:#fff;padding:20px;border-radius:12px;text-align:center;margin:20px 0;font-size:18px;font-weight:bold;box-shadow:0 4px 15px rgba(40,167,69,.3)}
    .tabs{display:flex;margin-bottom:20px;border-bottom:2px solid #e9ecef}
    .tab{padding:12px 24px;cursor:pointer;border-bottom:3px solid transparent;font-weight:bold;transition:all .3s}
    .tab:hover{background:#f8f9fa}
    .tab.active{border-bottom-color:#28a745;background:#d4edda;color:#155724}
    .tab-content{display:none}
    .tab-content.active{display:block}
    @keyframes pulse{0%{transform:scale(1);opacity:.8}50%{transform:scale(1.05);opacity:1}100%{transform:scale(1);opacity:.8}}
    .processing-animation{animation:pulse 2s ease-in-out infinite}
    .timeline{position:relative;margin:20px 0}
    .timeline-item{display:flex;align-items:center;margin:15px 0;padding:15px;background:#fff;border-radius:8px;border-left:4px solid #28a745}
    .timeline-date{font-weight:bold;min-width:100px;color:#28a745}
    .timeline-content{flex:1;margin-left:15px}
    .capability-matrix{display:grid;grid-template-columns:200px repeat(4,1fr);gap:1px;background:#dee2e6;border-radius:8px;overflow:hidden;margin:20px 0}
    .capability-header{background:#2d2d2d;color:#fff;padding:12px;font-weight:bold;text-align:center}
    .capability-cell{background:#fff;padding:10px;text-align:center;font-size:12px}
    .performance-indicator{display:inline-block;width:12px;height:12px;border-radius:50%;margin:0 2px}
    .perf-excellent{background:#28a745}
    .perf-good{background:#17a2b8}
    .perf-average{background:#ffc107}
    .perf-poor{background:#dc3545}
  </style>
</head>
<body>
  <div class="nav-bar">
    <div class="nav-title">üëÅÔ∏è Vision-Language Models: GPT-4V, Gemini, Claude</div>
    <a href="index.html" class="nav-home">üè† Home</a>
    <a href="clip-architecture.html" class="nav-prev">‚Üê CLIP Architecture</a>
    <a href="vision-language-action.html" class="nav-next">Next: Vision-Language-Action ‚Üí</a>
  </div>

  <div class="container">
    <h1>üëÅÔ∏è Vision-Language Models: The Multimodal AI Revolution</h1>
    <p>Building on CLIP's foundation, modern <strong>Vision-Language Models (VLMs)</strong> like GPT-4V, Gemini, and Claude have revolutionized how AI systems understand and reason about images. These models don't just classify or retrieve - they <strong>converse, analyze, and reason</strong> about visual content using natural language, enabling applications from document analysis to creative assistance.</p>
    <div class="breakthrough-highlight">
      üåü From CLIP's breakthrough (2021) to conversational vision AI (2023): How joint embeddings evolved into multimodal reasoning systems that can see, understand, and discuss any image!
    </div>
  </div>

  <!-- (content unchanged; trimmed here for brevity in this message) -->
  <!-- Keep all your existing sections exactly as you shared them -->

  <!-- üü¢ Single consolidated script block (duplicates removed) -->
  <script>
    let selectedModel = 'gpt4v';
    let selectedFusion = 'early';
    let selectedOpenSourceModel = 'llava';
    let activeOpenSourceTab = 'llava-training';

    // Initialize on page load
    document.addEventListener('DOMContentLoaded', () => {
      const firstModelCard = document.querySelector('.model-comparison .model-card');
      if (firstModelCard) selectModel('gpt4v', firstModelCard);
      const firstFusionCard = document.querySelector('.fusion-card');
      if (firstFusionCard) selectFusion('early', firstFusionCard);

      // Safe attempts (only run if controls exist)
      if (document.getElementById('tokenVisualization')) generateTokenSequence();
      if (document.getElementById('attentionVisualization')) visualizeAttention();
      if (document.getElementById('benchmarkResults')) updateBenchmarks();
      if (document.getElementById('applicationShowcase')) showcaseApplications();
      if (document.getElementById('trainingSimulation')) simulateVLMTraining();
    });

    // ‚úÖ Unified, feature-complete selectModel (keeps your detailed analysis UI)
    function selectModel(modelId, element) {
      selectedModel = modelId;

      // Visual selection in the clicked group only
      const group = element.closest('.model-comparison') || document;
      group.querySelectorAll('.model-card').forEach(card => card.classList.remove('selected'));
      element.classList.add('selected');

      // Respect analysisLevel/detailLevel if present
      const analysisLevel = document.getElementById('analysisLevel')?.value || 'architecture';
      const detailLevel   = document.getElementById('detailLevel')?.value   || 'high';

      const architectureDetails = {
        'gpt4v': {
          architecture: {
            high: `
              <div class="step">
                <h4>üîç GPT-4V Architecture Deep Dive</h4>
                <div class="math-formula">
                  <strong>GPT-4V Processing Pipeline:</strong><br><br>
                  <strong>1. Vision Tokenization:</strong><br>
                  Image(H√óW√ó3) ‚Üí Patches(N√óP¬≤√ó3) ‚Üí ViT ‚Üí Visual_Tokens(N√ó1280)<br>
                  Where N ‚âà 1700 tokens for high-res images<br><br>
                  <strong>2. Projection to LLM Space:</strong><br>
                  V_projected = MLP(V_visual) ‚àà ‚Ñù^(N√ó12288)<br>
                  MLP: 1280 ‚Üí 4096 ‚Üí 12288 (with GELU activation)<br><br>
                  <strong>3. Token Stream Integration:</strong><br>
                  Sequence = [V_1, ..., V_1700, T_1, ..., T_M] (‚â§ 128K)<br><br>
                  <strong>4. Cross-Modal Processing:</strong><br>
                  Attention(Q, K, V) across visual + text tokens
                </div>
                <div class="architecture-flow" style="flex-direction: column;">
                  <div style="display:flex;justify-content:space-between;width:100%;gap:12px;">
                    <div class="arch-component vision">
                      <h5>üì∑ Custom ViT-G/14</h5>
                      <div style="font-size:11px">‚Ä¢ Params: 1.3B<br>‚Ä¢ Hidden: 1280<br>‚Ä¢ Patch: 14√ó14</div>
                    </div>
                    <div class="arch-arrow">‚Üí</div>
                    <div class="arch-component fusion">
                      <h5>üîó Vision Projector</h5>
                      <div style="font-size:11px">‚Ä¢ 1280‚Üí4096‚Üí12288 (GELU)<br>‚Ä¢ Dropout 0.1</div>
                    </div>
                    <div class="arch-arrow">‚Üí</div>
                    <div class="arch-component language">
                      <h5>üß† GPT-4 Transformer</h5>
                      <div style="font-size:11px">‚Ä¢ Hidden: 12,288<br>‚Ä¢ Context: 128K</div>
                    </div>
                  </div>
                </div>
              </div>`
          },
          dimensions: {
            high: `
              <div class="step">
                <h4>üìê GPT-4V Dimension Alignment Strategy</h4>
                <div class="math-formula">
                  Vision: ‚Ñù^(N√ó1280) ‚Üí Language: ‚Ñù^(M√ó12288)<br><br>
                  f(v)=GELU(W‚ÇÇ¬∑GELU(W‚ÇÅ¬∑v)) with W‚ÇÅ:1280‚Üí4096, W‚ÇÇ:4096‚Üí12288
                </div>
                <div class="code-block">
                  <div class="code-header">üíª GPT-4V-Style Dimension Alignment</div>
                  <button class="copy-button" onclick="copyCode(this)">üìã Copy</button>
<pre>class VisionProjector(nn.Module):
    def __init__(self, vision_dim=1280, language_dim=12288, hidden_dim=4096):
        super().__init__()
        self.projector = nn.Sequential(
            nn.Linear(vision_dim, hidden_dim),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, language_dim),
            nn.GELU(),
            nn.Dropout(0.1)
        )
    def forward(self, vision_features):
        return self.projector(vision_features)</pre>
                </div>
                <div class="warning"><strong>Trade-offs:</strong> +~52M params, possible bottleneck; <strong>Benefits:</strong> modularity, reuse pretraining.</div>
              </div>`
          },
          'training-data': { high: `
              <div class="step">
                <h4>üìä GPT-4V Training Data Composition (Estimated)</h4>
                <div class="metric-grid">
                  <div class="metric-card"><div class="metric-value">~10B</div><div class="metric-label">Image-Text Pairs</div></div>
                  <div class="metric-card"><div class="metric-value">üîí</div><div class="metric-label">Transparency</div></div>
                  <div class="metric-card"><div class="metric-value">$100M+</div><div class="metric-label">Est. Cost</div></div>
                  <div class="metric-card"><div class="metric-value">Mixed</div><div class="metric-label">Copyright</div></div>
                </div>
                <div class="warning"><strong>Concerns:</strong> copyright, transparency, bias.</div>
              </div>` },
          tokens: { high: `
              <div class="step">
                <h4>üé≠ GPT-4V Token Processing Strategy</h4>
                <div class="token-flow">
                  <div class="token special">[IMG_START]</div>
                  <div class="token image">patch_0_0</div><div class="token image">patch_0_1</div><div class="token image">...</div>
                  <div class="token special">[IMG_END]</div>
                  <div class="token text">Describe</div><div class="token text">this</div><div class="token text">image</div>
                </div>
              </div>` }
        },
        'gemini': {
          dimensions: { high: `
              <div class="step">
                <h4>üìê Gemini's Unified Dimension Strategy</h4>
                <div class="math-formula">
                  All modalities: d_model=2048 ‚Üí unified attention without projection.
                </div>
              </div>` },
          'training-data': { high: `
              <div class="step">
                <h4>üìä Gemini Training Data Composition</h4>
                <div class="info"><strong>Scale:</strong> Web + YouTube; multilingual; video-native.</div>
              </div>` }
        },
        'claude': {
          dimensions: { high: `
              <div class="step">
                <h4>üìê Claude 3 Constitutional Dimension Strategy</h4>
                <div class="math-formula">ViT-L/14 ‚Üí 1024D ‚Üí safety mask ‚Üí 4096D projection.</div>
              </div>` },
          'training-data': { high: `
              <div class="step">
                <h4>üìä Claude 3 Training Data Philosophy</h4>
                <div class="success">Quality-first curation; safety-aligned.</div>
              </div>` }
        }
      };

      const block = architectureDetails[modelId]?.[analysisLevel]?.[detailLevel];
      if (block) {
        const target = document.getElementById('architectureDetails');
        if (target) target.innerHTML = block;
      }
    }

    // ‚úÖ Single copy helper
    function copyCode(button) {
      const codeBlock = button.nextElementSibling;
      if (codeBlock && codeBlock.tagName === 'PRE') {
        const text = codeBlock.textContent;
        navigator.clipboard.writeText(text).then(() => {
          const originalText = button.textContent;
          button.textContent = '‚úÖ Copied';
          setTimeout(() => { button.textContent = originalText; }, 2000);
        });
      }
    }

    // Token viz
    function generateTokenSequence() {
      const resolution = parseInt(document.getElementById('imageResolution').value);
      const patchSize = parseInt(document.getElementById('patchSize').value);
      const textInput = document.getElementById('textInput').value;
      const patchesPerSide = resolution / patchSize;
      const visualTokens = patchesPerSide * patchesPerSide;
      const textTokens = Math.ceil(textInput.split(' ').length * 1.3);

      let tokenHtml = '<div class="token-flow">';
      tokenHtml += '<div class="token special">[BOS]</div>';
      for (let i = 0; i < Math.min(visualTokens, 20); i++) tokenHtml += `<div class="token image">IMG_${i}</div>`;
      if (visualTokens > 20) tokenHtml += `<div class="token image">... +${visualTokens - 20}</div>`;
      const words = textInput.split(' ');
      words.slice(0,15).forEach(w => tokenHtml += `<div class="token text">${w}</div>`);
      if (words.length>15) tokenHtml += `<div class="token text">...</div>`;
      tokenHtml += '<div class="token special">[EOS]</div></div>';

      document.getElementById('tokenVisualization').innerHTML = `
        <div class="training-simulation">
          <h4>üé≠ Token Sequence Analysis</h4>
          ${tokenHtml}
          <div class="metric-grid" style="margin-top:20px;">
            <div class="metric-card"><div class="metric-value">${visualTokens}</div><div class="metric-label">Visual Tokens</div></div>
            <div class="metric-card"><div class="metric-value">${textTokens}</div><div class="metric-label">Text Tokens</div></div>
            <div class="metric-card"><div class="metric-value">${visualTokens + textTokens + 2}</div><div class="metric-label">Total Sequence</div></div>
            <div class="metric-card"><div class="metric-value">${(resolution*resolution*3/1024/1024).toFixed(1)}MB</div><div class="metric-label">Raw Image Size</div></div>
          </div>
        </div>`;
    }

    // Fusion
    function selectFusion(fusionType, element) {
      selectedFusion = fusionType;
      const group = element.closest('.fusion-strategies') || document;
      group.querySelectorAll('.fusion-card').forEach(card => card.classList.remove('selected'));
      element.classList.add('selected');

      const fusionDetails = {
        early: { pros:['Simple','Max interaction','Unified processing'], cons:['High compute','Memory heavy','May lose modality traits'], use_case:'Tight VQA integration' },
        late:  { pros:['Modality-optimized','Lower compute','Flexible'], cons:['Less cross talk','Miss fine relations'], use_case:'Image cls + text metadata' },
        cross: { pros:['Balanced','Controlled','Interpretable'], cons:['More complex','Moderate compute'], use_case:'Docs & complex reasoning' },
        adaptive:{ pros:['Dynamic','Task-adaptive','Peak performance'], cons:['Complex train','Hard interpret','Expensive'], use_case:'Multi-task research' }
      };
      const d = fusionDetails[fusionType];
      document.getElementById('fusionAnalysis').innerHTML = `
        <div class="step" style="margin-top:20px;">
          <h4>üîÄ ${fusionType[0].toUpperCase()+fusionType.slice(1)} Fusion Analysis</h4>
          <div class="success"><strong>‚úÖ Advantages:</strong><br>‚Ä¢ ${d.pros.join('<br>‚Ä¢ ')}</div>
          <div class="warning"><strong>‚ö†Ô∏è Trade-offs:</strong><br>‚Ä¢ ${d.cons.join('<br>‚Ä¢ ')}</div>
          <div class="info"><strong>üéØ Best Use Case:</strong><br>${d.use_case}</div>
        </div>`;
    }

    // Attention viz
    function visualizeAttention() {
      const queryText = document.getElementById('queryText').value;
      const attentionHead = document.getElementById('attentionHead').value;
      const patternsByHead = {
        '1':[0.8,0.6,0.4,0.2,0.9,0.3,0.1,0.5],
        '2':[0.3,0.7,0.9,0.5,0.2,0.8,0.4,0.6],
        '3':[0.5,0.2,0.3,0.9,0.6,0.1,0.8,0.4],
        '4':[0.1,0.3,0.2,0.4,0.5,0.6,0.9,0.8]
      };
      const patterns = patternsByHead[attentionHead];
      let matrixHtml = '<div class="attention-matrix"><h4>Cross-Modal Attention Matrix</h4>';
      matrixHtml += '<div class="matrix-grid" style="grid-template-columns: repeat(9,1fr);">';
      matrixHtml += '<div class="matrix-cell" style="background:#2d2d2d;color:#fff;font-weight:bold;">Query\\Image</div>';
      for (let i=0;i<8;i++) matrixHtml += `<div class="matrix-cell" style="background:#2d2d2d;color:#fff;font-weight:bold;">Patch ${i+1}</div>`;
      const queryWords = queryText.split(' ').slice(0,4);
      queryWords.forEach(word=>{
        matrixHtml += `<div class="matrix-cell" style="background:#2d2d2d;color:#fff;font-weight:bold;">${word}</div>`;
        patterns.forEach(a=>{
          const v = a * (0.8 + Math.random()*0.4);
          const cls = v>0.7?'attention-high':v>0.4?'attention-medium':'attention-low';
          matrixHtml += `<div class="matrix-cell ${cls}">${v.toFixed(2)}</div>`;
        });
      });
      matrixHtml += '</div></div>';
      document.getElementById('attentionVisualization').innerHTML = `
        <div class="training-simulation">
          <h4>üîç Attention Pattern: "${queryText}"</h4>
          ${matrixHtml}
          <div class="info" style="margin-top:15px;"><strong>üß† Head ${attentionHead}:</strong> ${getAttentionAnalysis(attentionHead)}</div>
        </div>`;
    }
    function getAttentionAnalysis(head){
      return ({
        '1':'Object focus / localization.',
        '2':'Color & texture features.',
        '3':'Spatial relations & layout.',
        '4':'OCR & text patches.'
      })[head];
    }

    // Benchmarks
    function updateBenchmarks() {
      const category = document.getElementById('benchmarkCategory').value;
      const metric = document.getElementById('evaluationMetric').value;
      const benchmarkData = {
        general: { accuracy:{'GPT-4V':87.2,'Gemini Pro':84.3,'Claude 3':86.1}, speed:{'GPT-4V':12,'Gemini Pro':18,'Claude 3':15}, cost:{'GPT-4V':0.010,'Gemini Pro':0.0025,'Claude 3':0.0048} },
        reasoning:{ accuracy:{'GPT-4V':78.5,'Gemini Pro':82.1,'Claude 3':79.8}, speed:{'GPT-4V':8,'Gemini Pro':12,'Claude 3':10}, cost:{'GPT-4V':0.015,'Gemini Pro':0.004,'Claude 3':0.007} },
        ocr:      { accuracy:{'GPT-4V':94.1,'Gemini Pro':91.8,'Claude 3':95.2}, speed:{'GPT-4V':15,'Gemini Pro':22,'Claude 3':18}, cost:{'GPT-4V':0.008,'Gemini Pro':0.002,'Claude 3':0.004} }
      };
      const results = document.getElementById('benchmarkResults');
      if (!benchmarkData[category]) {
        results.innerHTML = `<div class="warning"><strong>No data for "${category}".</strong> Try General, Reasoning, or OCR.</div>`;
        return;
      }
      const data = benchmarkData[category][metric];
      let tableHtml = `
        <table class="benchmark-table">
          <tr><th>Model</th><th>${metric==='accuracy'?'Accuracy (%)':metric==='speed'?'Speed (tokens/sec)':'Cost ($/image)'}</th><th>Ranking</th></tr>`;
      const sorted = Object.entries(data).sort((a,b)=> metric==='cost'? a[1]-b[1] : b[1]-a[1]);
      sorted.forEach(([model,value],idx)=>{
        const scoreClass = idx===0?'score-excellent':idx===1?'score-good':'score-average';
        const val = metric==='accuracy'? value.toFixed(1) : metric==='cost'? value.toFixed(4) : String(value);
        tableHtml += `<tr><td><strong>${model}</strong></td><td class="${scoreClass}">${val}</td><td>#${idx+1}</td></tr>`;
      });
      tableHtml += '</table>';
      results.innerHTML = `
        <div class="training-simulation">
          <h4>üìä ${category[0].toUpperCase()+category.slice(1)} Benchmarks - ${metric[0].toUpperCase()+metric.slice(1)}</h4>
          ${tableHtml}
          <div class="info" style="margin-top:15px;"><strong>üìà Notes:</strong> ${getBenchmarkNotes(category,metric)}</div>
        </div>`;
    }
    function getBenchmarkNotes(category, metric) {
      const notes = {
        general:{accuracy:'Average across MMMU/VQAv2/TextVQA',speed:'A100 tokens/sec',cost:'Approx 2024 pricing'},
        reasoning:{accuracy:'CLEVR / Visual7W style sets',speed:'Heavier compute per token',cost:'Longer generations'},
        ocr:{accuracy:'Doc OCR accuracy',speed:'Typically fastest',cost:'Doc pipelines are optimized'}
      };
      return notes[category]?.[metric] || '‚Äî';
    }

    // Open Source Explorer helpers (added to avoid dead buttons)
    function exploreOpenSource() {
      const category = document.getElementById('openSourceCategory').value;
      const useCase = document.getElementById('useCase').value;
      const data = {
        models: ['LLaVA-1.6-34B','InstructBLIP-13B','MiniGPT-4-13B'],
        perf:   [69.5,64.2,58.7],
        cost:   [500000,200000,100000],
        params: [34,13,13]
      };
      let rows = data.models.map((m,i)=>`
        <tr>
          <td><strong>${m}</strong></td>
          <td class="${data.perf[i]>65?'score-excellent':data.perf[i]>60?'score-good':'score-average'}">${data.perf[i].toFixed(1)}%</td>
          <td class="${data.cost[i]<200000?'score-excellent':data.cost[i]<400000?'score-good':'score-average'}">$${data.cost[i].toLocaleString()}</td>
          <td>${data.params[i]}B</td>
          <td>${getBestUseCase(m)}</td>
        </tr>`).join('');
      document.getElementById('openSourceResults').innerHTML = `
        <div class="training-simulation">
          <h4>üìä Open Source VLM Analysis: ${category.toUpperCase()}</h4>
          <div class="benchmark-table"><table>
            <tr><th>Model</th><th>Performance</th><th>Training Cost</th><th>Parameters</th><th>Best For</th></tr>
            ${rows}
          </table></div>
          <div class="success"><strong>üéØ Recommendation for ${useCase}:</strong><br>${getRecommendation(useCase)}</div>
        </div>`;
    }
    function getBestUseCase(model){
      if (model.includes('MiniGPT')) return 'Rapid prototyping / research';
      if (model.includes('InstructBLIP')) return 'Instruction following / education';
      if (model.includes('34B')) return 'Higher performance production';
      return 'General multimodal tasks';
    }
    function getRecommendation(useCase){
      const map = {
        research:'Start with MiniGPT-4 or LLaVA-7B; iterate quickly.',
        production:'LLaVA-13B/34B for strong perf + transparency.',
        education:'InstructBLIP for instruction fidelity.',
        customization:'LLaVA for easy domain fine-tuning.'
      };
      return map[useCase] || 'Pick based on your data + budget.';
    }
    function selectOpenSourceModel(id, el){
      selectedOpenSourceModel = id;
      const group = el.closest('.model-comparison') || document;
      group.querySelectorAll('.model-card').forEach(c=>c.classList.remove('selected'));
      el.classList.add('selected');
      const details = {
        llava:`<div class="info"><strong>LLaVA-1.6 (34B)</strong>: Vicuna + CLIP ViT-L/14; strong general perf; easy finetune.</div>`,
        instructblip:`<div class="info"><strong>InstructBLIP (13B)</strong>: Q-Former; great instruction following.</div>`,
        minigpt4:`<div class="info"><strong>MiniGPT-4 (13B)</strong>: Minimal alignment; fast to train.</div>`
      };
      const target = document.getElementById('openSourceModelDetails');
      if (target) target.innerHTML = `<div class="step">${details[id]||''}</div>`;
    }

    // Tabs
    function switchOpenSourceTab(tabId, el){
      // Scoped to the training block
      const container = el?.closest('.tabs')?.parentElement || document;
      container.querySelectorAll('.tab').forEach(t=>t.classList.remove('active'));
      el?.classList.add('active');
      ['llava-training','blip-training','custom-training','deployment'].forEach(id=>{
        const node = document.getElementById(id);
        if (node) node.classList.toggle('active', id===tabId);
      });
    }
    function switchTab(tabName, el){
      // Scoped to the Implementation & API Usage block
      const container = el?.closest('.tabs')?.parentElement || document;
      container.querySelectorAll('.tab').forEach(t=>t.classList.remove('active'));
      el?.classList.add('active');
      ['openai','google','anthropic','comparison'].forEach(id=>{
        const node = document.getElementById(id);
        if (node) node.classList.toggle('active', id===tabName);
      });
    }

    // Comparison button fallback (simple table)
    function generateComparison(){
      const benchmark = document.getElementById('benchmarkType')?.value || 'mmmu';
      const factor = document.getElementById('costFactor')?.value || 'training';
      const data = [
        {name:'GPT-4V', perf:87, training:'$100M+', inference:'high', total:'high'},
        {name:'Gemini Pro', perf:84, training:'$50M+', inference:'medium', total:'medium'},
        {name:'Claude 3', perf:86, training:'$30M+', inference:'medium', total:'medium'}
      ];
      const col = factor==='training'?'training':factor==='inference'?'inference':'total';
      const rows = data.map(d=>`<tr><td><strong>${d.name}</strong></td><td>${d.perf}%</td><td>${d[col]}</td></tr>`).join('');
      document.getElementById('comparisonChart').innerHTML = `
        <div class="training-simulation">
          <h4>üìä ${benchmark.toUpperCase()} ‚Äî ${factor[0].toUpperCase()+factor.slice(1)}</h4>
          <table class="benchmark-table">
            <tr><th>Model</th><th>Perf. (proxy)</th><th>${factor[0].toUpperCase()+factor.slice(1)}</th></tr>
            ${rows}
          </table>
          <div class="info">Lightweight preview; tune with your real numbers as needed.</div>
        </div>`;
    }

    // Applications
    function showcaseApplications() {
      const industry = document.getElementById('industryVertical').value;
      const useCase = document.getElementById('useCaseType').value;
      const apps = {
        healthcare:{ analysis:{title:'üè• Medical Imaging Analysis',desc:'Automated radiology report generation',examples:['X-ray detection','MRI analysis','Pathology slides'],roi:'60% faster, maintain accuracy'} },
        education:{ creative:{title:'üé® Interactive Learning',desc:'AI tutors that can see student work',examples:['Handwriting feedback','Art critique','Diagram explanation'],roi:'85% engagement increase'} }
      };
      const app = apps[industry]?.[useCase] || {title:'Demo',desc:'Example applications',examples:['A','B','C'],roi:'‚Äî'};
      document.getElementById('applicationShowcase').innerHTML = `
        <div class="training-simulation">
          <div class="model-card" style="border-color:#28a745;">
            <div class="model-name">${app.title}</div>
            <div style="margin:15px 0;">${app.desc}</div>
            <div class="model-capabilities">
              <h5>Key Applications:</h5>
              ${app.examples.map(e=>`<div class="capability"><span class="capability-icon">‚úÖ</span><span>${e}</span></div>`).join('')}
            </div>
            <div class="success" style="margin-top:15px;"><strong>üéØ Impact:</strong> ${app.roi}</div>
          </div>
        </div>`;
    }

    // Training simulator
    function simulateVLMTraining() {
      const stage = document.getElementById('trainingStage').value;
      const dataset = document.getElementById('datasetType').value;
      const scale = document.getElementById('trainingScale').value;
      const stages = {
        pretrain:{desc:'Large-scale joint pretraining',dur:{small:'3‚Äì5d',medium:'1‚Äì2w',large:'2‚Äì4w'},comp:{small:'10‚Äì50 GPUs',medium:'100‚Äì500 GPUs',large:'1000+ GPUs'},loss:'LM + contrastive',out:'General multimodal understanding'},
        instruction:{desc:'Instruction tuning on curated data',dur:{small:'1‚Äì2d',medium:'3‚Äì5d',large:'1‚Äì2w'},comp:{small:'5‚Äì20 GPUs',medium:'50‚Äì100 GPUs',large:'200‚Äì500 GPUs'},loss:'Xent on responses',out:'Follows visual instructions'},
        rlhf:{desc:'Human preference optimization',dur:{small:'1d',medium:'2‚Äì3d',large:'~1w'},comp:{small:'5‚Äì10 GPUs',medium:'20‚Äì50 GPUs',large:'100‚Äì200 GPUs'},loss:'PPO + KL',out:'Preference-aligned responses'},
        'fine-tune':{desc:'Domain-specific fine-tune',dur:{small:'<1d',medium:'1‚Äì3d',large:'~1w'},comp:{small:'1‚Äì8 GPUs',medium:'8‚Äì32 GPUs',large:'50‚Äì100 GPUs'},loss:'Task-specific',out:'Domain specialization'}
      };
      const d = stages[stage];
      document.getElementById('trainingSimulation').innerHTML = `
        <div class="training-simulation">
          <div class="processing-animation" style="text-align:center;margin:20px 0;">
            <div style="font-size:2em;">üéì</div>
            <div style="font-weight:bold;">Simulating ${stage.toUpperCase()}...</div>
          </div>
          <div class="metric-grid">
            <div class="metric-card"><div class="metric-value">${d.dur[scale]}</div><div class="metric-label">Duration</div></div>
            <div class="metric-card"><div class="metric-value">${d.comp[scale]}</div><div class="metric-label">Compute</div></div>
            <div class="metric-card"><div class="metric-value">${dataset}</div><div class="metric-label">Dataset</div></div>
            <div class="metric-card"><div class="metric-value">${scale}</div><div class="metric-label">Scale</div></div>
          </div>
          <div class="step">
            <h4>üìã Stage: ${stage[0].toUpperCase()+stage.slice(1)}</h4>
            <div class="info"><strong>Process:</strong> ${d.desc}<br><strong>Loss:</strong> ${d.loss}<br><strong>Outcome:</strong> ${d.out}</div>
          </div>
        </div>`;
    }
  </script>
</body>
</html>
