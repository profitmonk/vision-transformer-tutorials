<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Patch Embeddings & Positional Encoding - Mathematical Deep Dive</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #1a1a1a 0%, #2d2d2d 100%);
            color: #e0e0e0;
            line-height: 1.6;
        }
        
        .container {
            background: #ffffff;
            color: #2d2d2d;
            border-radius: 20px;
            padding: 30px;
            margin: 20px 0;
            border: 1px solid #e0e0e0;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
        }
        
        .nav-bar {
            background: #2d2d2d;
            color: white;
            padding: 15px 30px;
            border-radius: 15px;
            margin: 20px 0;
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
        }
        
        .nav-home {
            background: #ffffff;
            color: #2d2d2d;
            padding: 8px 16px;
            border-radius: 6px;
            text-decoration: none;
            font-weight: bold;
            transition: all 0.3s ease;
        }
        
        .nav-home:hover {
            background: #f8f9fa;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
        }
        
        .nav-title {
            font-size: 1.2em;
            font-weight: bold;
            flex: 1;
            min-width: 300px;
        }
        
        .nav-prev, .nav-next {
            background: #28a745;
            color: white;
            padding: 8px 16px;
            border-radius: 6px;
            text-decoration: none;
            font-weight: bold;
            transition: all 0.3s ease;
        }
        
        .nav-prev {
            background: #6c757d;
        }
        
        .nav-prev:hover {
            background: #5a6268;
            transform: translateY(-2px);
        }
        
        .nav-next:hover {
            background: #218838;
            transform: translateY(-2px);
        }
        
        .step {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            padding: 25px;
            margin: 20px 0;
            border-radius: 15px;
            border-left: 4px solid #2d2d2d;
        }
        
        .math-formula {
            background: #f8f9fa;
            border: 2px solid #e9ecef;
            padding: 20px;
            border-radius: 12px;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
            text-align: left;
            font-size: 14px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
            overflow-x: auto;
        }
        
        .code-block {
            background: #2d2d2d;
            color: #e0e0e0;
            padding: 20px;
            border-radius: 10px;
            margin: 15px 0;
            font-family: 'Courier New', monospace;
            overflow-x: auto;
            border: 1px solid #4a4a4a;
        }
        
        .interactive-demo {
            background: #f8f9fa;
            border: 2px solid #e9ecef;
            border-radius: 15px;
            padding: 25px;
            margin: 25px 0;
        }
        
        .demo-title {
            font-size: 1.4em;
            font-weight: bold;
            margin-bottom: 20px;
            text-align: center;
            color: #2d2d2d;
        }
        
        .controls {
            display: flex;
            gap: 20px;
            margin: 20px 0;
            flex-wrap: wrap;
            align-items: center;
        }
        
        .control-group {
            display: flex;
            flex-direction: column;
            gap: 5px;
            min-width: 150px;
        }
        
        label {
            font-weight: bold;
            color: #2d2d2d;
            font-size: 14px;
        }
        
        input, select {
            padding: 8px 12px;
            border: 1px solid #dadce0;
            border-radius: 6px;
            background: #ffffff;
            color: #2d2d2d;
            font-size: 14px;
        }
        
        button {
            background: #2d2d2d;
            border: none;
            color: white;
            padding: 12px 24px;
            border-radius: 8px;
            cursor: pointer;
            font-weight: bold;
            transition: all 0.3s ease;
            font-size: 14px;
        }
        
        button:hover {
            background: #1a1a1a;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
        }
        
        .parameter-box {
            background: #e3f2fd;
            border-left: 4px solid #2196f3;
            padding: 20px;
            margin: 15px 0;
            border-radius: 8px;
        }
        
        .warning {
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            color: #856404;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
        
        .success {
            background: #d4edda;
            border-left: 4px solid #28a745;
            color: #155724;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
        
        .info {
            background: #d1ecf1;
            border-left: 4px solid #17a2b8;
            color: #0c5460;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
        
        .danger {
            background: #f8d7da;
            border-left: 4px solid #dc3545;
            color: #721c24;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: #ffffff;
            border: 1px solid #e9ecef;
            border-radius: 8px;
            overflow: hidden;
        }
        
        th {
            background: #2d2d2d;
            color: white;
            padding: 15px;
            text-align: center;
            font-weight: bold;
            font-size: 14px;
        }
        
        td {
            padding: 12px 15px;
            text-align: center;
            border-bottom: 1px solid #e9ecef;
            font-size: 14px;
        }
        
        .optimal {
            background: #d4edda;
            font-weight: bold;
        }
        
        .moderate {
            background: #fff3cd;
        }
        
        .poor {
            background: #f8d7da;
        }
        
        .patch-grid {
            display: grid;
            gap: 2px;
            margin: 20px auto;
            max-width: 500px;
            background: #2d2d2d;
            padding: 15px;
            border-radius: 12px;
        }
        
        .patch-cell {
            background: #28a745;
            aspect-ratio: 1;
            border-radius: 4px;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-size: 10px;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.3s ease;
            position: relative;
        }
        
        .patch-cell:hover {
            background: #ffc107;
            transform: scale(1.1);
            z-index: 10;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
        }
        
        .patch-cell.selected {
            background: #dc3545;
            transform: scale(1.05);
        }
        
        .embedding-viz {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin: 25px 0;
            flex-wrap: wrap;
            gap: 15px;
        }
        
        .embedding-stage {
            background: #2d2d2d;
            color: white;
            padding: 20px;
            border-radius: 12px;
            text-align: center;
            min-width: 150px;
            flex: 1;
        }
        
        .stage-title {
            font-size: 12px;
            color: #28a745;
            font-weight: bold;
            margin-bottom: 8px;
        }
        
        .stage-content {
            font-size: 16px;
            font-weight: bold;
            margin: 8px 0;
        }
        
        .stage-description {
            font-size: 11px;
            color: #adb5bd;
            margin-top: 8px;
        }
        
        .flow-arrow {
            font-size: 24px;
            color: #dc3545;
            font-weight: bold;
            margin: 0 10px;
        }
        
        .complexity-analysis {
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 25px;
            border-radius: 12px;
            margin: 25px 0;
        }
        
        .scaling-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 25px 0;
        }
        
        .scaling-card {
            background: #f8f9fa;
            border: 2px solid #e9ecef;
            border-radius: 12px;
            padding: 20px;
            text-align: center;
            transition: all 0.3s ease;
        }
        
        .scaling-card:hover {
            border-color: #2d2d2d;
            transform: translateY(-5px);
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.1);
        }
        
        .scaling-metric {
            font-size: 24px;
            font-weight: bold;
            color: #2d2d2d;
            margin: 10px 0;
        }
        
        .scaling-label {
            font-size: 14px;
            color: #666;
            font-weight: bold;
        }
        
        .scaling-description {
            font-size: 12px;
            color: #888;
            margin-top: 8px;
        }
        
        .position-encoding-viz {
            display: grid;
            gap: 2px;
            margin: 20px auto;
            max-width: 300px;
            background: #2d2d2d;
            padding: 10px;
            border-radius: 8px;
            box-sizing: border-box;
        }
        
        .pos-cell {
            aspect-ratio: 1;
            border-radius: 2px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 8px;
            color: white;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.2s ease;
            min-height: 20px;
            max-height: 30px;
            min-width: 20px;
            max-width: 30px;
            box-sizing: border-box;
        }
        
        .pos-cell:hover {
            transform: scale(1.2);
            z-index: 10;
            border: 2px solid white;
        }
        
        .memory-breakdown {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 12px;
            padding: 20px;
            margin: 20px 0;
        }
        
        .memory-row {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 12px 0;
            border-bottom: 1px solid #e9ecef;
        }
        
        .memory-row:last-child {
            border-bottom: none;
            font-weight: bold;
            background: #e3f2fd;
            padding: 15px;
            border-radius: 8px;
            margin-top: 15px;
        }
        
        .progress-bar {
            width: 100%;
            height: 25px;
            background: #e9ecef;
            border-radius: 12px;
            overflow: hidden;
            margin: 15px 0;
        }
        
        .progress-fill {
            height: 100%;
            background: linear-gradient(135deg, #28a745, #20c997);
            transition: width 0.5s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-size: 12px;
            font-weight: bold;
        }
        
        .comparison-table {
            margin: 25px 0;
        }
        
        .highlight {
            background: #ffeb3b;
            padding: 2px 4px;
            border-radius: 3px;
            font-weight: bold;
        }
        
        .architecture-diagram {
            background: #f8f9fa;
            border: 2px solid #e9ecef;
            border-radius: 15px;
            padding: 25px;
            margin: 25px 0;
            text-align: center;
        }
        
        .layer-flow {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin: 20px 0;
        }
        
        .layer-box {
            background: #2d2d2d;
            color: white;
            padding: 15px;
            border-radius: 8px;
            min-width: 120px;
            text-align: center;
            flex: 1;
        }
        
        .layer-title {
            font-size: 11px;
            color: #28a745;
            font-weight: bold;
            margin-bottom: 5px;
        }
        
        .layer-content {
            font-size: 14px;
            font-weight: bold;
        }
        
        .layer-detail {
            font-size: 10px;
            color: #adb5bd;
            margin-top: 5px;
        }
        
        .decision-matrix {
            display: grid;
            grid-template-columns: 1fr 2fr 2fr 2fr;
            gap: 1px;
            background: #e9ecef;
            border-radius: 8px;
            overflow: hidden;
            margin: 25px 0;
        }
        
        .matrix-cell {
            background: white;
            padding: 12px;
            text-align: center;
            font-size: 13px;
        }
        
        .matrix-header {
            background: #2d2d2d;
            color: white;
            font-weight: bold;
        }
        
        .matrix-row-header {
            background: #f8f9fa;
            font-weight: bold;
            text-align: left;
        }

                .code-container {
            background-color: #ffffff;
            border: 1px solid #e9ecef;
            border-radius: 8px;
            padding: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .comment {
            color: #6a737d;
            font-style: italic;
        }
        .step-header {
            color: #0366d6;
            font-weight: bold;
            margin-top: 20px;
            margin-bottom: 10px;
        }
        .code-line {
            margin: 5px 0;
            padding-left: 0;
        }
        .indent-1 { padding-left: 20px; }
        .indent-2 { padding-left: 40px; }
        .indent-3 { padding-left: 60px; }
        .indent-4 { padding-left: 80px; }
        .variable {
            color: #e36209;
            font-weight: bold;
        }
        .dimensions {
            color: #28a745;
            font-weight: bold;
        }
        .function {
            color: #6f42c1;
        }
        
        @media (max-width: 768px) {
            .controls {
                flex-direction: column;
                align-items: stretch;
            }
            
            .control-group {
                min-width: auto;
            }
            
            .embedding-viz {
                flex-direction: column;
            }
            
            .flow-arrow {
                transform: rotate(90deg);
                margin: 10px 0;
            }
            
            .scaling-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="nav-bar">
        <div class="nav-title">üìê Patch Embeddings & Positional Encoding - Mathematical Deep Dive</div>
        <a href="vit-fundamentals.html" class="nav-prev">‚Üê Previous: ViT Fundamentals</a>
        <a href="index.html" class="nav-home">üè† Home</a>
        <a href="visual-attention.html" class="nav-next">Next: Visual Attention ‚Üí</a>
    </div>

    <div class="container">
        <h1>üìê Patch Embeddings & Positional Encoding Deep Dive</h1>
        <p>Master the mathematical foundations and architectural trade-offs of the most critical ViT design decisions. From patch size optimization to learned positional encodings, understand how these choices determine model performance, computational requirements, and architectural constraints.</p>
        
        <div class="info">
            <strong>üéØ What You'll Master:</strong> Patch size trade-off analysis, linear projection mathematics, 2D positional encoding variants, resolution transfer strategies, memory scaling laws, and production optimization techniques for patch embedding architectures.
        </div>
    </div>

    <div class="container">
        <h2>üî¨ The Patch Size Decision: Mathematical Foundation</h2>
        
        <div class="step">
            <h3>üìä The Fundamental Scaling Laws</h3>
            
            <p>Patch size is the most critical architectural decision in ViTs because it determines the computational complexity of every subsequent operation. Let's analyze the mathematical relationships:</p>
            
            <div class="math-formula">
                <strong>Core Scaling Relationships:</strong><br><br>
                
                Given image dimensions H √ó W and patch size P √ó P:<br><br>
                
                <strong>Sequence Length:</strong><br>
                N = (H/P) √ó (W/P) = (H √ó W) / P¬≤<br><br>
                
                <strong>Attention Complexity:</strong><br>
                ‚Ä¢ Memory: O(N¬≤) = O((H √ó W)¬≤ / P‚Å¥)<br>
                ‚Ä¢ Compute: O(N¬≤ √ó D) = O((H √ó W)¬≤ √ó D / P‚Å¥)<br><br>
                
                <strong>Critical Insight:</strong><br>
                Halving patch size ‚Üí 4√ó more tokens ‚Üí 16√ó more attention computation<br>
                Doubling patch size ‚Üí 4√ó fewer tokens ‚Üí 16√ó less attention computation
            </div>
            
            <div class="interactive-demo">
                <div class="demo-title">‚öñÔ∏è Patch Size Impact Calculator</div>
                
                <div class="controls">
                    <div class="control-group">
                        <label>Image Resolution:</label>
                        <input type="range" id="imageRes" min="224" max="1024" value="384" step="32">
                        <span id="imageResValue">384√ó384</span>
                    </div>
                    <div class="control-group">
                        <label>Patch Size:</label>
                        <input type="range" id="patchSize" min="4" max="64" value="16" step="4">
                        <span id="patchSizeValue">16√ó16</span>
                    </div>
                    <div class="control-group">
                        <label>Model Variant:</label>
                        <select id="modelVariant">
                            <option value="768">ViT-Base (768D)</option>
                            <option value="1024">ViT-Large (1024D)</option>
                            <option value="1280">ViT-Huge (1280D)</option>
                        </select>
                    </div>
                    <div class="control-group">
                        <label>Analysis Type:</label>
                        <select id="analysisType">
                            <option value="tokens">Token Count</option>
                            <option value="memory">Memory Analysis</option>
                            <option value="flops">FLOP Analysis</option>
                            <option value="comparison">Size Comparison</option>
                        </select>
                    </div>
                </div>
                
                <button onclick="analyzePatchImpact()">üìä Analyze Patch Impact</button>
                <div id="patchAnalysisResults"></div>
            </div>
        </div>
        
        <div class="step">
            <h3>üéØ The Information Density Trade-off</h3>
            
            <p>Each patch size represents a fundamental trade-off between spatial resolution and computational efficiency. Understanding this mathematically:</p>
            
            <div class="math-formula">
                <strong>Information Density Analysis:</strong><br><br>
                
                <strong>Spatial Information per Token:</strong><br>
                I_spatial = P¬≤ pixels per token<br><br>
                
                <strong>Effective Resolution:</strong><br>
                R_effective = ‚àöN = ‚àö((H √ó W) / P¬≤) = ‚àö(H √ó W) / P<br><br>
                
                <strong>Information Loss Factor:</strong><br>
                Loss = (Total_pixels - Preserved_spatial_relationships) / Total_pixels<br>
                ‚âà 1 - (1/P¬≤) for fine-grained patterns<br><br>
                
                <strong>Computational Cost per Bit of Information:</strong><br>
                Cost = O(N¬≤ √ó D) / (H √ó W) = O(D / P¬≤)
            </math-formula>
            
            <div class="complexity-analysis">
                <strong>‚ö° The Quadratic Scaling Challenge:</strong><br><br>
                
                The attention mechanism's O(N¬≤) complexity creates exponential memory growth:<br><br>
                
                <strong>For 512√ó512 image:</strong><br>
                ‚Ä¢ 8√ó8 patches: 4,096 tokens ‚Üí 16.8M attention elements per head<br>
                ‚Ä¢ 16√ó16 patches: 1,024 tokens ‚Üí 1.05M attention elements per head<br>
                ‚Ä¢ 32√ó32 patches: 256 tokens ‚Üí 65K attention elements per head<br><br>
                
                <strong>Memory scaling factor from 32√ó32 to 8√ó8: 258√ó</strong><br><br>
                
                This isn't just academic - it's the difference between running on consumer hardware vs requiring data center infrastructure.
            </div>
        </div>
    </div>

    <div class="container">
        <h2>üßÆ Linear Projection Mathematics</h2>
        
        <div class="step">
            <h3>üîÑ From Pixels to Embeddings: The Transformation</h3>
            
            <p>The patch embedding layer is fundamentally different from text embeddings. Instead of discrete lookup tables, vision transformers must learn continuous projections from pixel space to embedding space.</p>
            
            <div class="math-formula">
                <strong>Patch Embedding Transformation:</strong><br><br>
                
                <strong>Step 1: Patch Extraction</strong><br>
                x_patch ‚àà ‚Ñù^(N √ó (P¬≤ √ó C))<br>
                where N = number of patches, P¬≤ = patch area, C = channels<br><br>
                
                <strong>Step 2: Linear Projection</strong><br>
                E = x_patch √ó W_proj + b_proj<br><br>
                
                <strong>Weight Matrix Dimensions:</strong><br>
                W_proj ‚àà ‚Ñù^((P¬≤ √ó C) √ó D)<br>
                b_proj ‚àà ‚Ñù^D<br><br>
                
                <strong>Parameter Count:</strong><br>
                Params = (P¬≤ √ó C √ó D) + D = D √ó (P¬≤ √ó C + 1)<br><br>
                
                <strong>Output:</strong><br>
                E ‚àà ‚Ñù^(N √ó D) - embedded patch representations
            </math-formula>
            
            <div class="interactive-demo">
                <div class="demo-title">üîÑ Linear Projection Analyzer</div>
                
                <div class="controls">
                    <div class="control-group">
                        <label>Patch Size:</label>
                        <input type="range" id="projPatchSize" min="4" max="32" value="16" step="4">
                        <span id="projPatchSizeValue">16√ó16</span>
                    </div>
                    <div class="control-group">
                        <label>Embedding Dimension:</label>
                        <select id="projEmbedDim">
                            <option value="384">384 (ViT-Small)</option>
                            <option value="512">512</option>
                            <option value="768">768 (ViT-Base)</option>
                            <option value="1024">1024 (ViT-Large)</option>
                            <option value="1280">1280 (ViT-Huge)</option>
                        </select>
                    </div>
                    <div class="control-group">
                        <label>Channels:</label>
                        <select id="projChannels">
                            <option value="3">3 (RGB)</option>
                            <option value="4">4 (RGBA)</option>
                            <option value="1">1 (Grayscale)</option>
                        </select>
                    </div>
                </div>
                
                <button onclick="analyzeLinearProjection()">üßÆ Analyze Projection</button>
                <div id="projectionResults"></div>
            </div>
        </div>
        
        <div class="step">
            <h3>üí° The Learned Visual Vocabulary Concept</h3>
            
            <p>Unlike text transformers with fixed vocabularies, ViTs must <em>learn</em> their visual vocabulary through the projection matrix. This is a fundamental difference that affects initialization, training dynamics, and performance.</p>
            
            <div class="parameter-box">
                <strong>üîç Text vs Vision Embedding Comparison:</strong><br><br>
                
                <strong>Text Transformers:</strong><br>
                ‚Ä¢ Fixed vocabulary: 50,000 discrete tokens<br>
                ‚Ä¢ Lookup operation: O(1) complexity<br>
                ‚Ä¢ Each token has learned embedding vector<br>
                ‚Ä¢ No spatial relationships in vocabulary<br><br>
                
                <strong>Vision Transformers:</strong><br>
                ‚Ä¢ Infinite continuous space: any pixel combination possible<br>
                ‚Ä¢ Linear transformation: O(P¬≤ √ó C √ó D) complexity<br>
                ‚Ä¢ Must learn to cluster similar patches<br>
                ‚Ä¢ Spatial relationships must be learned<br>
                ‚Ä¢ Patch projection matrix acts as "vocabulary discovery"
            </div>
            
            <div class="code-block">
<strong>Pseudocode: Patch Embedding Implementation</strong>

def patch_embedding_forward(image, patch_size, embed_dim):
    """
    Convert image to patch embeddings
    
    Args:
        image: [H, W, C] input image
        patch_size: P (square patches)
        embed_dim: D embedding dimension
    
    Returns:
        embeddings: [N, D] where N = (H*W)/(P*P)
    """
    H, W, C = image.shape
    P = patch_size
    
    # Step 1: Extract patches
    # Reshape to [N, P*P*C] where N = number of patches
    N = (H // P) * (W // P)
    patches = extract_patches(image, patch_size)  # [N, P*P*C]
    
    # Step 2: Linear projection
    # W_proj: [P*P*C, D], b_proj: [D]
    embeddings = patches @ W_proj + b_proj  # [N, D]
    
    return embeddings

def extract_patches(image, patch_size):
    """Extract non-overlapping patches from image"""
    H, W, C = image.shape
    P = patch_size
    
    # Ensure image dimensions are divisible by patch size
    assert H % P == 0 and W % P == 0
    
    patches = []
    for i in range(0, H, P):
        for j in range(0, W, P):
            # Extract P√óP√óC patch and flatten
            patch = image[i:i+P, j:j+P, :].flatten()
            patches.append(patch)
    
    return np.stack(patches)  # [N, P*P*C]

# Parameter initialization (critical for vision)
def initialize_patch_projection(patch_size, channels, embed_dim):
    """Initialize patch embedding weights"""
    input_dim = patch_size * patch_size * channels
    
    # Xavier/Glorot initialization for linear layer
    limit = np.sqrt(6.0 / (input_dim + embed_dim))
    W_proj = np.random.uniform(-limit, limit, (input_dim, embed_dim))
    b_proj = np.zeros(embed_dim)
    
    return W_proj, b_proj
            </div>
        </div>
    </div>

    <div class="container">
        <h2>üìç 2D Positional Encoding: Spatial Relationships</h2>
        
        <div class="step">
            <h3>üåê The 2D Spatial Challenge</h3>
            
            <p>Text has natural 1D order, but images have 2D spatial structure. ViTs must encode both row and column positions, as well as global patch relationships.</p>
            
            <div class="math-formula">
                <strong>2D Positional Encoding Mathematics:</strong><br><br>
                
                <strong>Learnable Absolute Positions (Standard ViT):</strong><br>
                E_pos ‚àà ‚Ñù^((N+1) √ó D)<br>
                where N+1 includes CLS token position<br><br>
                
                <strong>Position Assignment:</strong><br>
                ‚Ä¢ Position 0: CLS token<br>
                ‚Ä¢ Position (i√ócols + j + 1): patch at row i, column j<br><br>
                
                <strong>Final Token Representation:</strong><br>
                z‚ÇÄ = [x_cls; x‚ÇÅE; x‚ÇÇE; ...; x_NE] + E_pos<br><br>
                
                <strong>Alternative: 2D Sinusoidal Encoding</strong><br>
                PE(pos, 2i) = sin(pos / 10000^(2i/d))<br>
                PE(pos, 2i+1) = cos(pos / 10000^(2i/d))<br>
                Applied separately to row and column positions
            </math-formula>
            
            <div class="interactive-demo">
                <div class="demo-title">üìç Positional Encoding Visualizer</div>
                
                <div class="controls">
                    <div class="control-group">
                        <label>Grid Size:</label>
                        <input type="range" id="posGridSize" min="4" max="16" value="8" step="1">
                        <span id="posGridSizeValue">8√ó8</span>
                    </div>
                    <div class="control-group">
                        <label>Encoding Type:</label>
                        <select id="posEncodingType">
                            <option value="learnable">Learnable (Standard)</option>
                            <option value="sinusoidal">Sinusoidal</option>
                            <option value="2d_sinusoidal">2D Sinusoidal</option>
                            <option value="relative">Relative</option>
                        </select>
                    </div>
                    <div class="control-group">
                        <label>Visualization:</label>
                        <select id="posVisualization">
                            <option value="position_id">Position IDs</option>
                            <option value="similarity">Position Similarity</option>
                            <option value="distance">Spatial Distance</option>
                        </select>
                    </div>
                </div>
                
                <button onclick="visualizePositionalEncoding()">üé® Generate Visualization</button>
                <div id="positionalEncodingViz"></div>
                <div id="positionalEncodingAnalysis"></div>
            </div>
        </div>
        
        <div class="step">
            <h3>‚öñÔ∏è Positional Encoding Variants: Trade-off Analysis</h3>
            
            <div class="comparison-table">
                <table>
                    <tr>
                        <th>Encoding Type</th>
                        <th>Parameters</th>
                        <th>Advantages</th>
                        <th>Disadvantages</th>
                        <th>Best Use Case</th>
                    </tr>
                    <tr>
                        <td><strong>Learnable Absolute</strong></td>
                        <td class="moderate">(N+1)√óD</td>
                        <td>Flexible, adapts to data<br>Works well for fixed resolution</td>
                        <td>Fixed sequence length<br>Poor generalization to new sizes</td>
                        <td class="optimal">Standard ViT applications</td>
                    </tr>
                    <tr>
                        <td><strong>Sinusoidal</strong></td>
                        <td class="optimal">0 (fixed)</td>
                        <td>No parameters<br>Extrapolates to longer sequences</td>
                        <td>1D order assumption<br>Suboptimal for 2D spatial data</td>
                        <td>Resource-constrained settings</td>
                    </tr>
                    <tr>
                        <td><strong>2D Sinusoidal</strong></td>
                        <td class="optimal">0 (fixed)</td>
                        <td>True 2D awareness<br>Resolution independent</td>
                        <td>Complex implementation<br>May underperform learnable</td>
                        <td>Variable resolution applications</td>
                    </tr>
                    <tr>
                        <td><strong>Relative</strong></td>
                        <td class="poor">2N√óD approx</td>
                        <td>Translation invariant<br>Better generalization</td>
                        <td>Higher complexity<br>More parameters</td>
                        <td class="moderate">Research & specialized tasks</td>
                    </tr>
                </table>
            </div>
            
    <div class="code-container">
        <h1>Positional Encoding Implementations</h1>
        
        <div class="step-header"># Pseudocode: Positional Encoding Implementations</div>
        
        <div class="example-box">
<div class="code-line">
    <span class="function">def</span> <span class="variable">learnable_positional_encoding</span>(<span class="variable">num_patches</span>, <span class="variable">embed_dim</span>):
</div>
<div class="code-line indent-1">
    <span class="comment">"""Standard ViT learnable positions"""</span>
</div>
<div class="code-line indent-1">
    <span class="comment"># +1 for CLS token</span>
</div>
<div class="code-line indent-1">
    <span class="variable">pos_embed</span> = <span class="variable">nn</span>.<span class="function">Parameter</span>(<span class="variable">torch</span>.<span class="function">zeros</span>(1, <span class="variable">num_patches</span> + 1, <span class="variable">embed_dim</span>))
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-1">
    <span class="comment"># Initialize with truncated normal</span>
</div>
<div class="code-line indent-1">
    <span class="variable">nn</span>.<span class="variable">init</span>.<span class="function">trunc_normal_</span>(<span class="variable">pos_embed</span>, std=0.02)
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-1">
    <span class="function">return</span> <span class="variable">pos_embed</span>
</div>
<div class="code-line">
    
</div>
<div class="code-line">
    
</div>
<div class="code-line">
    <span class="function">def</span> <span class="variable">sinusoidal_positional_encoding</span>(<span class="variable">num_patches</span>, <span class="variable">embed_dim</span>):
</div>
<div class="code-line indent-1">
    <span class="comment">"""1D sinusoidal encoding applied to flattened 2D positions"""</span>
</div>
<div class="code-line indent-1">
    <span class="variable">position</span> = <span class="variable">torch</span>.<span class="function">arange</span>(<span class="variable">num_patches</span> + 1).<span class="function">unsqueeze</span>(1)
</div>
<div class="code-line indent-1">
    <span class="variable">div_term</span> = <span class="variable">torch</span>.<span class="function">exp</span>(<span class="variable">torch</span>.<span class="function">arange</span>(0, <span class="variable">embed_dim</span>, 2) * 
</div>
<div class="code-line indent-2">
    -(<span class="variable">math</span>.<span class="function">log</span>(10000.0) / <span class="variable">embed_dim</span>))
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-1">
    <span class="variable">pos_embed</span> = <span class="variable">torch</span>.<span class="function">zeros</span>(<span class="variable">num_patches</span> + 1, <span class="variable">embed_dim</span>)
</div>
<div class="code-line indent-1">
    <span class="variable">pos_embed</span>[:, 0::2] = <span class="variable">torch</span>.<span class="function">sin</span>(<span class="variable">position</span> * <span class="variable">div_term</span>)
</div>
<div class="code-line indent-1">
    <span class="variable">pos_embed</span>[:, 1::2] = <span class="variable">torch</span>.<span class="function">cos</span>(<span class="variable">position</span> * <span class="variable">div_term</span>)
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-1">
    <span class="function">return</span> <span class="variable">pos_embed</span>.<span class="function">unsqueeze</span>(0)
</div>
<div class="code-line">
    
</div>
<div class="code-line">
    
</div>
<div class="code-line">
    <span class="function">def</span> <span class="variable">sinusoidal_2d_positional_encoding</span>(<span class="variable">height</span>, <span class="variable">width</span>, <span class="variable">embed_dim</span>):
</div>
<div class="code-line indent-1">
    <span class="comment">"""True 2D sinusoidal encoding"""</span>
</div>
<div class="code-line indent-1">
    <span class="comment"># Separate embeddings for height and width</span>
</div>
<div class="code-line indent-1">
    <span class="variable">h_embed_dim</span> = <span class="variable">embed_dim</span> // 2
</div>
<div class="code-line indent-1">
    <span class="variable">w_embed_dim</span> = <span class="variable">embed_dim</span> - <span class="variable">h_embed_dim</span>
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-1">
    <span class="comment"># Height positions</span>
</div>
<div class="code-line indent-1">
    <span class="variable">h_pos</span> = <span class="variable">torch</span>.<span class="function">arange</span>(<span class="variable">height</span>).<span class="function">unsqueeze</span>(1)
</div>
<div class="code-line indent-1">
    <span class="variable">h_div_term</span> = <span class="variable">torch</span>.<span class="function">exp</span>(<span class="variable">torch</span>.<span class="function">arange</span>(0, <span class="variable">h_embed_dim</span>, 2) * 
</div>
<div class="code-line indent-2">
    -(<span class="variable">math</span>.<span class="function">log</span>(10000.0) / <span class="variable">h_embed_dim</span>))
</div>
<div class="code-line indent-1">
    <span class="variable">h_embed</span> = <span class="variable">torch</span>.<span class="function">zeros</span>(<span class="variable">height</span>, <span class="variable">h_embed_dim</span>)
</div>
<div class="code-line indent-1">
    <span class="variable">h_embed</span>[:, 0::2] = <span class="variable">torch</span>.<span class="function">sin</span>(<span class="variable">h_pos</span> * <span class="variable">h_div_term</span>)
</div>
<div class="code-line indent-1">
    <span class="variable">h_embed</span>[:, 1::2] = <span class="variable">torch</span>.<span class="function">cos</span>(<span class="variable">h_pos</span> * <span class="variable">h_div_term</span>)
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-1">
    <span class="comment"># Width positions</span>
</div>
<div class="code-line indent-1">
    <span class="variable">w_pos</span> = <span class="variable">torch</span>.<span class="function">arange</span>(<span class="variable">width</span>).<span class="function">unsqueeze</span>(1)
</div>
<div class="code-line indent-1">
    <span class="variable">w_div_term</span> = <span class="variable">torch</span>.<span class="function">exp</span>(<span class="variable">torch</span>.<span class="function">arange</span>(0, <span class="variable">w_embed_dim</span>, 2) * 
</div>
<div class="code-line indent-2">
    -(<span class="variable">math</span>.<span class="function">log</span>(10000.0) / <span class="variable">w_embed_dim</span>))
</div>
<div class="code-line indent-1">
    <span class="variable">w_embed</span> = <span class="variable">torch</span>.<span class="function">zeros</span>(<span class="variable">width</span>, <span class="variable">w_embed_dim</span>)
</div>
<div class="code-line indent-1">
    <span class="variable">w_embed</span>[:, 0::2] = <span class="variable">torch</span>.<span class="function">sin</span>(<span class="variable">w_pos</span> * <span class="variable">w_div_term</span>)
</div>
<div class="code-line indent-1">
    <span class="variable">w_embed</span>[:, 1::2] = <span class="variable">torch</span>.<span class="function">cos</span>(<span class="variable">w_pos</span> * <span class="variable">w_div_term</span>)
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-1">
    <span class="comment"># Combine height and width embeddings for each patch</span>
</div>
<div class="code-line indent-1">
    <span class="variable">pos_embed</span> = <span class="variable">torch</span>.<span class="function">zeros</span>(<span class="variable">height</span> * <span class="variable">width</span> + 1, <span class="variable">embed_dim</span>)
</div>
<div class="code-line indent-1">
    <span class="variable">pos_embed</span>[0, :] = 0  <span class="comment"># CLS token</span>
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-1">
    <span class="function">for</span> <span class="variable">i</span> in <span class="function">range</span>(<span class="variable">height</span>):
</div>
<div class="code-line indent-2">
    <span class="function">for</span> <span class="variable">j</span> in <span class="function">range</span>(<span class="variable">width</span>):
</div>
<div class="code-line indent-3">
    <span class="variable">patch_idx</span> = <span class="variable">i</span> * <span class="variable">width</span> + <span class="variable">j</span> + 1
</div>
<div class="code-line indent-3">
    <span class="variable">pos_embed</span>[<span class="variable">patch_idx</span>, :<span class="variable">h_embed_dim</span>] = <span class="variable">h_embed</span>[<span class="variable">i</span>, :]
</div>
<div class="code-line indent-3">
    <span class="variable">pos_embed</span>[<span class="variable">patch_idx</span>, <span class="variable">h_embed_dim</span>:] = <span class="variable">w_embed</span>[<span class="variable">j</span>, :]
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-1">
    <span class="function">return</span> <span class="variable">pos_embed</span>.<span class="function">unsqueeze</span>(0)
</div>
<div class="code-line">
    
</div>
<div class="code-line">
    
</div>
<div class="code-line">
    <span class="function">def</span> <span class="variable">relative_positional_encoding</span>(<span class="variable">height</span>, <span class="variable">width</span>, <span class="variable">embed_dim</span>, <span class="variable">max_distance</span>=7):
</div>
<div class="code-line indent-1">
    <span class="comment">"""Relative 2D position encoding (simplified)"""</span>
</div>
<div class="code-line indent-1">
    <span class="comment"># This is complex - showing concept only</span>
</div>
<div class="code-line indent-1">
    <span class="variable">num_relative_positions</span> = (2 * <span class="variable">max_distance</span> + 1) ** 2
</div>
<div class="code-line indent-1">
    <span class="variable">relative_position_bias</span> = <span class="variable">nn</span>.<span class="function">Parameter</span>(
</div>
<div class="code-line indent-2">
    <span class="variable">torch</span>.<span class="function">zeros</span>(<span class="variable">num_relative_positions</span>, <span class="variable">embed_dim</span>)
</div>
<div class="code-line indent-1">
    )
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-1">
    <span class="comment"># Build relative position index for each patch pair</span>
</div>
<div class="code-line indent-1">
    <span class="comment"># Implementation details omitted for brevity</span>
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-1">
    <span class="function">return</span> <span class="variable">relative_position_bias</span>
</div>
        </div>
    </div>

    <div class="container">
        <h2>üîÑ Resolution Transfer & Adaptability</h2>
        
        <div class="step">
            <h3>üìè The Resolution Transfer Problem</h3>
            
            <p>A critical limitation of standard ViTs is their fixed resolution dependency. When you train on 224√ó224 images, the learned positional embeddings don't directly apply to 384√ó384 images. Understanding this mathematically:</p>
            
            <div class="math-formula">
                <strong>Resolution Transfer Mathematics:</strong><br><br>
                
                <strong>Training Resolution:</strong><br>
                N_train = (H_train / P)¬≤ patches<br>
                E_pos_train ‚àà ‚Ñù^((N_train + 1) √ó D)<br><br>
                
                <strong>New Resolution:</strong><br>
                N_new = (H_new / P)¬≤ patches<br>
                Need: E_pos_new ‚àà ‚Ñù^((N_new + 1) √ó D)<br><br>
                
                <strong>Interpolation Strategy:</strong><br>
                1. Reshape E_pos_train to 2D grid: [‚àöN_train, ‚àöN_train, D]<br>
                2. Interpolate to new grid: [‚àöN_new, ‚àöN_new, D]<br>
                3. Reshape back to sequence: [N_new, D]<br><br>
                
                <strong>Interpolation Quality:</strong><br>
                Quality ‚àù overlap between train and test position distributions<br>
                Best when N_new ‚âà N_train (similar resolution)
            </math-formula>
            
            <div class="interactive-demo">
                <div class="demo-title">üîÑ Resolution Transfer Simulator</div>
                
                <div class="controls">
                    <div class="control-group">
                        <label>Training Resolution:</label>
                        <select id="trainRes">
                            <option value="224">224√ó224</option>
                            <option value="384" selected>384√ó384</option>
                            <option value="512">512√ó512</option>
                        </select>
                    </div>
                    <div class="control-group">
                        <label>Target Resolution:</label>
                        <select id="targetRes">
                            <option value="224">224√ó224</option>
                            <option value="384">384√ó384</option>
                            <option value="512">512√ó512</option>
                            <option value="768" selected>768√ó768</option>
                            <option value="1024">1024√ó1024</option>
                        </select>
                    </div>
                    <div class="control-group">
                        <label>Interpolation Method:</label>
                        <select id="interpMethod">
                            <option value="bilinear">Bilinear</option>
                            <option value="bicubic">Bicubic</option>
                            <option value="nearest">Nearest Neighbor</option>
                        </select>
                    </div>
                </div>
                
                <button onclick="simulateResolutionTransfer()">üîÑ Simulate Transfer</button>
                <div id="resolutionTransferResults"></div>
            </div>
        </div>
        
        <div class="step">
            <h3>üõ†Ô∏è Advanced Resolution Adaptation Strategies</h3>
            
            <div class="parameter-box">
                <strong>Production Resolution Transfer Techniques:</strong><br><br>
                
                <strong>1. Bicubic Interpolation (Most Common):</strong><br>
                ‚Ä¢ Smooth interpolation between known positions<br>
                ‚Ä¢ Works well for moderate resolution changes (2√ó or less)<br>
                ‚Ä¢ Used in most production ViT implementations<br><br>
                
                <strong>2. Multi-Scale Training:</strong><br>
                ‚Ä¢ Train on multiple resolutions simultaneously<br>
                ‚Ä¢ Model learns resolution-invariant features<br>
                ‚Ä¢ Best for applications with variable input sizes<br><br>
                
                <strong>3. Adaptive Positional Encoding:</strong><br>
                ‚Ä¢ Use relative positions instead of absolute<br>
                ‚Ä¢ Better generalization but more complex<br>
                ‚Ä¢ Research direction for flexible architectures<br><br>
                
                <strong>4. Fine-tuning at Target Resolution:</strong><br>
                ‚Ä¢ Transfer weights, then fine-tune on target resolution<br>
                ‚Ä¢ Most accurate but requires additional training<br>
                ‚Ä¢ Used for high-stakes applications
            </parameter-box>
        </div>
    </div>

    <div class="container">
        <h2>‚ö° Memory Scaling & Production Constraints</h2>
        
        <div class="step">
            <h3>üíæ Complete Memory Analysis</h3>
            
            <p>Understanding exact memory requirements is critical for production deployment. Let's break down every component mathematically:</p>
            
            <div class="interactive-demo">
                <div class="demo-title">üíæ Production Memory Calculator</div>
                
                <div class="controls">
                    <div class="control-group">
                        <label>Image Resolution:</label>
                        <input type="range" id="memImageRes" min="224" max="1024" value="384" step="32">
                        <span id="memImageResValue">384√ó384</span>
                    </div>
                    <div class="control-group">
                        <label>Patch Size:</label>
                        <input type="range" id="memPatchSize" min="4" max="32" value="16" step="4">
                        <span id="memPatchSizeValue">16√ó16</span>
                    </div>
                    <div class="control-group">
                        <label>Batch Size:</label>
                        <input type="range" id="memBatchSize" min="1" max="32" value="8" step="1">
                        <span id="memBatchSizeValue">8</span>
                    </div>
                    <div class="control-group">
                        <label>Model Size:</label>
                        <select id="memModelSize">
                            <option value="base">ViT-Base (768D, 12L)</option>
                            <option value="large">ViT-Large (1024D, 24L)</option>
                            <option value="huge">ViT-Huge (1280D, 32L)</option>
                        </select>
                    </div>
                    <div class="control-group">
                        <label>Precision:</label>
                        <select id="memPrecision">
                            <option value="fp32">FP32</option>
                            <option value="fp16">FP16</option>
                            <option value="bf16">BF16</option>
                            <option value="int8">INT8 (Inference)</option>
                        </select>
                    </div>
                </div>
                
                <button onclick="calculateProductionMemory()">üíª Calculate Memory Requirements</button>
                <div id="memoryCalculationResults"></div>
            </div>
        </div>
        
        <div class="step">
            <h3>üéØ Hardware-Specific Optimization Strategies</h3>
            
            <div class="scaling-grid">
                <div class="scaling-card">
                    <div class="scaling-label">Consumer GPUs</div>
                    <div class="scaling-metric">‚â§ 24GB</div>
                    <div class="scaling-description">
                        RTX 3090/4090<br>
                        Max: 384√ó384, patch 16√ó16<br>
                        Batch size: 4-8
                    </div>
                </div>
                
                <div class="scaling-card">
                    <div class="scaling-label">Professional GPUs</div>
                    <div class="scaling-metric">40-80GB</div>
                    <div class="scaling-description">
                        A100/H100<br>
                        Max: 512√ó512, patch 14√ó14<br>
                        Batch size: 16-32
                    </div>
                </div>
                
                <div class="scaling-card">
                    <div class="scaling-label">Multi-GPU Setups</div>
                    <div class="scaling-metric">>80GB</div>
                    <div class="scaling-description">
                        8√óA100<br>
                        Max: 1024√ó1024, any patch<br>
                        Batch size: 64+
                    </div>
                </div>
            </div>
            
            <div class="danger">
                <strong>‚ö†Ô∏è Critical Memory Bottlenecks:</strong><br><br>
                
                ‚Ä¢ <strong>Attention Maps:</strong> O(N¬≤) scaling - dominates at high resolution<br>
                ‚Ä¢ <strong>Gradient Storage:</strong> 2√ó model parameters during training<br>
                ‚Ä¢ <strong>Optimizer States:</strong> 2-3√ó model parameters for Adam<br>
                ‚Ä¢ <strong>Activation Checkpointing:</strong> Trade compute for memory (2-3√ó slower)<br><br>
                
                <strong>Emergency Optimization:</strong><br>
                ‚Ä¢ Reduce batch size before reducing model quality<br>
                ‚Ä¢ Use gradient accumulation to maintain effective batch size<br>
                ‚Ä¢ Consider patch size increase as last resort
            </danger>
        </div>
    </div>

    <div class="container">
        <h2>üöÄ Advanced Patch Embedding Strategies</h2>
        
        <div class="step">
            <h3>üîß Beyond Standard Patches: Modern Innovations</h3>
            
            <div class="architecture-diagram">
                <h4>üèóÔ∏è Hierarchical Patch Embedding Architecture</h4>
                
                <div class="layer-flow">
                    <div class="layer-box">
                        <div class="layer-title">Stage 1</div>
                        <div class="layer-content">4√ó4 patches</div>
                        <div class="layer-detail">Fine details<br>High resolution</div>
                    </div>
                    <div class="flow-arrow">‚Üí</div>
                    <div class="layer-box">
                        <div class="layer-title">Stage 2</div>
                        <div class="layer-content">8√ó8 patches</div>
                        <div class="layer-detail">Medium features<br>Pooled resolution</div>
                    </div>
                    <div class="flow-arrow">‚Üí</div>
                    <div class="layer-box">
                        <div class="layer-title">Stage 3</div>
                        <div class="layer-content">16√ó16 patches</div>
                        <div class="layer-detail">Object parts<br>Lower resolution</div>
                    </div>
                    <div class="flow-arrow">‚Üí</div>
                    <div class="layer-box">
                        <div class="layer-title">Stage 4</div>
                        <div class="layer-content">32√ó32 patches</div>
                        <div class="layer-detail">Global context<br>Lowest resolution</div>
                    </div>
                </div>
                
                <div class="info">
                    <strong>üí° Hierarchical Benefits:</strong><br>
                    ‚Ä¢ Captures multi-scale information like CNNs<br>
                    ‚Ä¢ Reduces computational cost through progressive downsampling<br>
                    ‚Ä¢ Better performance on tasks requiring multi-scale understanding<br>
                    ‚Ä¢ Used in PiT, Swin Transformer, and other advanced architectures
                </div>
            </div>
        </div>
        
        <div class="step">
            <h3>üß† Advanced Embedding Techniques</h3>
            
    <div class="code-container">
        <h1>Advanced Patch Embedding Strategies</h1>
        
        <div class="step-header"># Pseudocode: Advanced Patch Embedding Strategies</div>
        
        <div class="example-box">
<div class="code-line">
    <span class="function">class</span> <span class="variable">ConvolutionalPatchEmbedding</span>:
</div>
<div class="code-line indent-1">
    <span class="comment">"""Use convolutional layers instead of linear projection"""</span>
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-1">
    <span class="function">def</span> <span class="variable">__init__</span>(<span class="variable">self</span>, <span class="variable">patch_size</span>, <span class="variable">embed_dim</span>, <span class="variable">in_channels</span>=3):
</div>
<div class="code-line indent-2">
    <span class="comment"># Convolution with kernel=patch_size, stride=patch_size</span>
</div>
<div class="code-line indent-2">
    <span class="variable">self</span>.<span class="variable">projection</span> = <span class="function">Conv2D</span>(
</div>
<div class="code-line indent-3">
    <span class="variable">in_channels</span>=<span class="variable">in_channels</span>,
</div>
<div class="code-line indent-3">
    <span class="variable">out_channels</span>=<span class="variable">embed_dim</span>,
</div>
<div class="code-line indent-3">
    <span class="variable">kernel_size</span>=<span class="variable">patch_size</span>,
</div>
<div class="code-line indent-3">
    <span class="variable">stride</span>=<span class="variable">patch_size</span>
</div>
<div class="code-line indent-2">
    )
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-1">
    <span class="function">def</span> <span class="variable">forward</span>(<span class="variable">self</span>, <span class="variable">x</span>):
</div>
<div class="code-line indent-2">
    <span class="comment"># x: <span class="dimensions">[B, H, W, C]</span></span>
</div>
<div class="code-line indent-2">
    <span class="variable">x</span> = <span class="variable">self</span>.<span class="variable">projection</span>(<span class="variable">x</span>)  <span class="comment"># <span class="dimensions">[B, H/P, W/P, D]</span></span>
</div>
<div class="code-line indent-2">
    <span class="variable">x</span> = <span class="variable">x</span>.<span class="function">flatten</span>(1, 2)    <span class="comment"># <span class="dimensions">[B, N, D]</span></span>
</div>
<div class="code-line indent-2">
    <span class="function">return</span> <span class="variable">x</span>
</div>
<div class="code-line">
    
</div>
<div class="code-line">
    
</div>
<div class="code-line">
    <span class="function">class</span> <span class="variable">OverlappingPatchEmbedding</span>:
</div>
<div class="code-line indent-1">
    <span class="comment">"""Overlapping patches for better locality"""</span>
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-1">
    <span class="function">def</span> <span class="variable">__init__</span>(<span class="variable">self</span>, <span class="variable">patch_size</span>, <span class="variable">stride</span>, <span class="variable">embed_dim</span>, <span class="variable">in_channels</span>=3):
</div>
<div class="code-line indent-2">
    <span class="variable">self</span>.<span class="variable">projection</span> = <span class="function">Conv2D</span>(
</div>
<div class="code-line indent-3">
    <span class="variable">in_channels</span>=<span class="variable">in_channels</span>,
</div>
<div class="code-line indent-3">
    <span class="variable">out_channels</span>=<span class="variable">embed_dim</span>,
</div>
<div class="code-line indent-3">
    <span class="variable">kernel_size</span>=<span class="variable">patch_size</span>,
</div>
<div class="code-line indent-3">
    <span class="variable">stride</span>=<span class="variable">stride</span>,  <span class="comment"># stride < patch_size for overlap</span>
</div>
<div class="code-line indent-3">
    <span class="variable">padding</span>=(<span class="variable">patch_size</span> - <span class="variable">stride</span>) // 2
</div>
<div class="code-line indent-2">
    )
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-1">
    <span class="function">def</span> <span class="variable">forward</span>(<span class="variable">self</span>, <span class="variable">x</span>):
</div>
<div class="code-line indent-2">
    <span class="variable">x</span> = <span class="variable">self</span>.<span class="variable">projection</span>(<span class="variable">x</span>)
</div>
<div class="code-line indent-2">
    <span class="variable">x</span> = <span class="variable">x</span>.<span class="function">flatten</span>(1, 2)
</div>
<div class="code-line indent-2">
    <span class="function">return</span> <span class="variable">x</span>
</div>
<div class="code-line">
    
</div>
<div class="code-line">
    
</div>
<div class="code-line">
    <span class="function">class</span> <span class="variable">HierarchicalPatchEmbedding</span>:
</div>
<div class="code-line indent-1">
    <span class="comment">"""Multi-scale patch embedding like PiT"""</span>
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-1">
    <span class="function">def</span> <span class="variable">__init__</span>(<span class="variable">self</span>, <span class="variable">patch_sizes</span>, <span class="variable">embed_dims</span>, <span class="variable">in_channels</span>=3):
</div>
<div class="code-line indent-2">
    <span class="variable">self</span>.<span class="variable">stages</span> = []
</div>
<div class="code-line indent-2">
    <span class="variable">prev_dim</span> = <span class="variable">in_channels</span>
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-2">
    <span class="function">for</span> <span class="variable">patch_size</span>, <span class="variable">embed_dim</span> in <span class="function">zip</span>(<span class="variable">patch_sizes</span>, <span class="variable">embed_dims</span>):
</div>
<div class="code-line indent-3">
    <span class="variable">stage</span> = <span class="function">Conv2D</span>(
</div>
<div class="code-line indent-4">
    <span class="variable">in_channels</span>=<span class="variable">prev_dim</span>,
</div>
<div class="code-line indent-4">
    <span class="variable">out_channels</span>=<span class="variable">embed_dim</span>,
</div>
<div class="code-line indent-4">
    <span class="variable">kernel_size</span>=<span class="variable">patch_size</span>,
</div>
<div class="code-line indent-4">
    <span class="variable">stride</span>=<span class="variable">patch_size</span>
</div>
<div class="code-line indent-3">
    )
</div>
<div class="code-line indent-3">
    <span class="variable">self</span>.<span class="variable">stages</span>.<span class="function">append</span>(<span class="variable">stage</span>)
</div>
<div class="code-line indent-3">
    <span class="variable">prev_dim</span> = <span class="variable">embed_dim</span>
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-1">
    <span class="function">def</span> <span class="variable">forward</span>(<span class="variable">self</span>, <span class="variable">x</span>):
</div>
<div class="code-line indent-2">
    <span class="variable">features</span> = []
</div>
<div class="code-line indent-2">
    <span class="function">for</span> <span class="variable">stage</span> in <span class="variable">self</span>.<span class="variable">stages</span>:
</div>
<div class="code-line indent-3">
    <span class="variable">x</span> = <span class="variable">stage</span>(<span class="variable">x</span>)
</div>
<div class="code-line indent-3">
    <span class="variable">features</span>.<span class="function">append</span>(<span class="variable">x</span>.<span class="function">flatten</span>(1, 2))
</div>
<div class="code-line indent-3">
    <span class="comment"># Could add downsampling here</span>
</div>
<div class="code-line indent-2">
    <span class="function">return</span> <span class="variable">features</span>
</div>
<div class="code-line">
    
</div>
<div class="code-line">
    
</div>
<div class="code-line">
    <span class="function">class</span> <span class="variable">AdaptivePatchEmbedding</span>:
</div>
<div class="code-line indent-1">
    <span class="comment">"""Adaptive patch sizes based on content"""</span>
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-1">
    <span class="function">def</span> <span class="variable">__init__</span>(<span class="variable">self</span>, <span class="variable">base_patch_size</span>, <span class="variable">embed_dim</span>, <span class="variable">in_channels</span>=3):
</div>
<div class="code-line indent-2">
    <span class="variable">self</span>.<span class="variable">base_patch_size</span> = <span class="variable">base_patch_size</span>
</div>
<div class="code-line indent-2">
    <span class="variable">self</span>.<span class="variable">embed_dim</span> = <span class="variable">embed_dim</span>
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-2">
    <span class="comment"># Multiple projection layers for different patch sizes</span>
</div>
<div class="code-line indent-2">
    <span class="variable">self</span>.<span class="variable">projections</span> = {
</div>
<div class="code-line indent-3">
    'small': <span class="function">Conv2D</span>(<span class="variable">in_channels</span>, <span class="variable">embed_dim</span>, 8, 8),
</div>
<div class="code-line indent-3">
    'medium': <span class="function">Conv2D</span>(<span class="variable">in_channels</span>, <span class="variable">embed_dim</span>, 16, 16),
</div>
<div class="code-line indent-3">
    'large': <span class="function">Conv2D</span>(<span class="variable">in_channels</span>, <span class="variable">embed_dim</span>, 32, 32)
</div>
<div class="code-line indent-2">
    }
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-2">
    <span class="comment"># Content-aware selection network</span>
</div>
<div class="code-line indent-2">
    <span class="variable">self</span>.<span class="variable">selector</span> = <span class="function">ContentSelector</span>(<span class="variable">in_channels</span>)
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-1">
    <span class="function">def</span> <span class="variable">forward</span>(<span class="variable">self</span>, <span class="variable">x</span>):
</div>
<div class="code-line indent-2">
    <span class="comment"># Analyze content to choose patch sizes</span>
</div>
<div class="code-line indent-2">
    <span class="variable">patch_size_map</span> = <span class="variable">self</span>.<span class="variable">selector</span>(<span class="variable">x</span>)
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-2">
    <span class="comment"># Apply different patch sizes to different regions</span>
</div>
<div class="code-line indent-2">
    <span class="comment"># Implementation details omitted for brevity</span>
</div>
<div class="code-line indent-2">
    <span class="function">return</span> <span class="variable">adaptive_patches</span>
</div>
<div class="code-line">
    
</div>
<div class="code-line">
    
</div>
<div class="code-line">
    <span class="function">def</span> <span class="variable">patch_embedding_initialization</span>(<span class="variable">patch_size</span>, <span class="variable">channels</span>, <span class="variable">embed_dim</span>):
</div>
<div class="code-line indent-1">
    <span class="comment">"""Proper initialization for patch embedding"""</span>
</div>
<div class="code-line indent-1">
    <span class="comment"># For convolutional patch embedding</span>
</div>
<div class="code-line indent-1">
    <span class="variable">fan_out</span> = <span class="variable">embed_dim</span> * <span class="variable">patch_size</span> * <span class="variable">patch_size</span>
</div>
<div class="code-line indent-1">
    <span class="variable">fan_in</span> = <span class="variable">channels</span> * <span class="variable">patch_size</span> * <span class="variable">patch_size</span>
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-1">
    <span class="comment"># He initialization for ReLU-like activations</span>
</div>
<div class="code-line indent-1">
    <span class="comment"># Xavier for linear activations</span>
</div>
<div class="code-line indent-1">
    <span class="function">if</span> <span class="variable">activation</span> == 'relu':
</div>
<div class="code-line indent-2">
    <span class="variable">std</span> = <span class="variable">math</span>.<span class="function">sqrt</span>(2.0 / <span class="variable">fan_in</span>)
</div>
<div class="code-line indent-1">
    <span class="function">else</span>:  <span class="comment"># linear/gelu</span>
</div>
<div class="code-line indent-2">
    <span class="variable">std</span> = <span class="variable">math</span>.<span class="function">sqrt</span>(2.0 / (<span class="variable">fan_in</span> + <span class="variable">fan_out</span>))
</div>
<div class="code-line">
    
</div>
<div class="code-line indent-1">
    <span class="function">return</span> <span class="variable">torch</span>.<span class="function">normal</span>(0, <span class="variable">std</span>, size=(<span class="variable">embed_dim</span>, <span class="variable">channels</span>, <span class="variable">patch_size</span>, <span class="variable">patch_size</span>))
</div>
        </div>
    </div>

    <div class="container">
        <h2>üéØ Decision Framework: Choosing Optimal Parameters</h2>
        
        <div class="step">
            <h3>üß≠ Production Decision Matrix</h3>
            
            <p>Use this systematic framework to choose patch size and embedding parameters for your specific application:</p>
            
            <div class="decision-matrix">
                <div class="matrix-cell matrix-header">Application Type</div>
                <div class="matrix-cell matrix-header">Recommended Patch Size</div>
                <div class="matrix-cell matrix-header">Reasoning</div>
                <div class="matrix-cell matrix-header">Alternative Approaches</div>
                
                <div class="matrix-cell matrix-row-header">ImageNet Classification</div>
                <div class="matrix-cell optimal">16√ó16</div>
                <div class="matrix-cell">Balanced efficiency/detail<br>Objects typically >32px</div>
                <div class="matrix-cell">14√ó14 for ViT-Huge<br>8√ó8 if fine details matter</div>
                
                <div class="matrix-cell matrix-row-header">Medical Imaging</div>
                <div class="matrix-cell moderate">8√ó8 or 4√ó4</div>
                <div class="matrix-cell">Critical fine details<br>Small pathological features</div>
                <div class="matrix-cell">Hierarchical patches<br>Multi-scale training</div>
                
                <div class="matrix-cell matrix-row-header">Satellite/Aerial</div>
                <div class="matrix-cell optimal">32√ó32</div>
                <div class="matrix-cell">Large-scale patterns<br>High resolution images</div>
                <div class="matrix-cell">Adaptive patching<br>Multi-resolution input</div>
                
                <div class="matrix-cell matrix-row-header">Face Recognition</div>
                <div class="matrix-cell moderate">16√ó16 or 8√ó8</div>
                <div class="matrix-cell">Facial features scale<br>Need eye/nose detail</div>
                <div class="matrix-cell">Overlapping patches<br>Attention to key regions</div>
                
                <div class="matrix-cell matrix-row-header">Object Detection</div>
                <div class="matrix-cell moderate">Variable/Hierarchical</div>
                <div class="matrix-cell">Multi-scale objects<br>Need all detail levels</div>
                <div class="matrix-cell">DETR-style approach<br>FPN-like hierarchies</div>
                
                <div class="matrix-cell matrix-row-header">Mobile/Edge</div>
                <div class="matrix-cell poor">32√ó32 or larger</div>
                <div class="matrix-cell">Memory/compute constraints<br>Real-time requirements</div>
                <div class="matrix-cell">Model distillation<br>Quantization techniques</div>
            </div>
        </div>
        
        <div class="step">
            <h3>üìä Interactive Decision Helper</h3>
            
            <div class="interactive-demo">
                <div class="demo-title">üéØ Patch Size Decision Helper</div>
                
                <div class="controls">
                    <div class="control-group">
                        <label>Application Domain:</label>
                        <select id="appDomain">
                            <option value="general">General Classification</option>
                            <option value="medical">Medical Imaging</option>
                            <option value="satellite">Satellite/Aerial</option>
                            <option value="face">Face Recognition</option>
                            <option value="detection">Object Detection</option>
                            <option value="mobile">Mobile/Edge</option>
                            <option value="custom">Custom Application</option>
                        </select>
                    </div>
                    <div class="control-group">
                        <label>Typical Object Size:</label>
                        <select id="objectSize">
                            <option value="tiny">Tiny (<16px)</option>
                            <option value="small">Small (16-32px)</option>
                            <option value="medium">Medium (32-64px)</option>
                            <option value="large">Large (64-128px)</option>
                            <option value="huge">Huge (>128px)</option>
                        </select>
                    </div>
                    <div class="control-group">
                        <label>Hardware Constraint:</label>
                        <select id="hardwareConstraint">
                            <option value="none">No Constraint</option>
                            <option value="consumer">Consumer GPU (‚â§24GB)</option>
                            <option value="mobile">Mobile/Edge Device</option>
                            <option value="cloud">Cloud/Data Center</option>
                        </select>
                    </div>
                    <div class="control-group">
                        <label>Performance Priority:</label>
                        <select id="performancePriority">
                            <option value="accuracy">Maximum Accuracy</option>
                            <option value="balanced">Balanced</option>
                            <option value="speed">Maximum Speed</option>
                            <option value="memory">Memory Efficiency</option>
                        </select>
                    </div>
                </div>
                
                <button onclick="generateRecommendation()">üéØ Get Recommendation</button>
                <div id="recommendationResults"></div>
            </div>
        </div>
        
        <div class="success">
            <strong>üéì Key Takeaways:</strong><br>
            ‚Ä¢ Patch size is the most critical architectural decision in ViTs<br>
            ‚Ä¢ Memory scales as O(1/P‚Å¥) - quadratic in inverse patch area<br>
            ‚Ä¢ Smaller patches preserve detail but require massive compute/data<br>
            ‚Ä¢ Positional encoding choice affects generalization to new resolutions<br>
            ‚Ä¢ Production deployment requires careful memory budgeting<br>
            ‚Ä¢ Advanced techniques (hierarchical, overlapping) can overcome limitations<br>
            ‚Ä¢ Always validate your choice with computational and memory constraints
        </div>
    </div>

    <script>
        // Global variables for calculations
        const modelSpecs = {
            base: { dim: 768, layers: 12, heads: 12 },
            large: { dim: 1024, layers: 24, heads: 16 },
            huge: { dim: 1280, layers: 32, heads: 16 }
        };

        const precisionBytes = {
            fp32: 4, fp16: 2, bf16: 2, int8: 1
        };

        function updateSliderValues() {
            document.getElementById('imageResValue').textContent = 
                document.getElementById('imageRes').value + '√ó' + document.getElementById('imageRes').value;
            document.getElementById('patchSizeValue').textContent = 
                document.getElementById('patchSize').value + '√ó' + document.getElementById('patchSize').value;
            document.getElementById('projPatchSizeValue').textContent = 
                document.getElementById('projPatchSize').value + '√ó' + document.getElementById('projPatchSize').value;
            document.getElementById('posGridSizeValue').textContent = 
                document.getElementById('posGridSize').value + '√ó' + document.getElementById('posGridSize').value;
            document.getElementById('memImageResValue').textContent = 
                document.getElementById('memImageRes').value + '√ó' + document.getElementById('memImageRes').value;
            document.getElementById('memPatchSizeValue').textContent = 
                document.getElementById('memPatchSize').value + '√ó' + document.getElementById('memPatchSize').value;
            document.getElementById('memBatchSizeValue').textContent = 
                document.getElementById('memBatchSize').value;
        }

        function analyzePatchImpact() {
            const imageRes = parseInt(document.getElementById('imageRes').value);
            const patchSize = parseInt(document.getElementById('patchSize').value);
            const embedDim = parseInt(document.getElementById('modelVariant').value);
            const analysisType = document.getElementById('analysisType').value;
            
            const patchesPerSide = imageRes / patchSize;
            const numPatches = patchesPerSide * patchesPerSide;
            const seqLen = numPatches + 1; // +1 for CLS token
            
            let html = `<div class="step"><h4>üìä Patch Impact Analysis: ${patchSize}√ó${patchSize} patches</h4>`;
            
            if (analysisType === 'tokens') {
                html += `
                    <div class="embedding-viz">
                        <div class="embedding-stage">
                            <div class="stage-title">Image</div>
                            <div class="stage-content">${imageRes}√ó${imageRes}</div>
                            <div class="stage-description">${(imageRes * imageRes * 3 / 1024).toFixed(0)}K pixels</div>
                        </div>
                        <div class="flow-arrow">‚Üí</div>
                        <div class="embedding-stage">
                            <div class="stage-title">Patches</div>
                            <div class="stage-content">${numPatches}</div>
                            <div class="stage-description">${patchesPerSide}√ó${patchesPerSide} grid</div>
                        </div>
                        <div class="flow-arrow">‚Üí</div>
                        <div class="embedding-stage">
                            <div class="stage-title">Sequence</div>
                            <div class="stage-content">${seqLen}</div>
                            <div class="stage-description">+1 CLS token</div>
                        </div>
                    </div>
                    
                    <div class="parameter-box">
                        <strong>Tokenization Analysis:</strong><br>
                        ‚Ä¢ <strong>Pixels per patch:</strong> ${patchSize * patchSize * 3} (${patchSize}¬≤√ó3 channels)<br>
                        ‚Ä¢ <strong>Information compression:</strong> ${(patchSize * patchSize * 3 / embedDim).toFixed(1)}:1 ratio<br>
                        ‚Ä¢ <strong>Spatial resolution:</strong> ${patchesPerSide}√ó${patchesPerSide} effective grid<br>
                        ‚Ä¢ <strong>Total parameters:</strong> ${((patchSize * patchSize * 3 * embedDim + embedDim) / 1e6).toFixed(2)}M for patch embedding
                    </div>
                `;
            } else if (analysisType === 'memory') {
                const bytesPerElement = 2; // FP16
                const patchEmbedMemory = numPatches * embedDim * bytesPerElement;
                const attentionMemory = seqLen * seqLen * 12 * bytesPerElement; // 12 heads
                const activationMemory = seqLen * embedDim * 12 * bytesPerElement; // 12 layers
                const totalMemory = patchEmbedMemory + attentionMemory + activationMemory;
                
                html += `
                    <div class="memory-breakdown">
                        <div class="memory-row">
                            <span><strong>Patch Embeddings:</strong></span>
                            <span>${(patchEmbedMemory / 1024 / 1024).toFixed(1)} MB</span>
                        </div>
                        <div class="memory-row">
                            <span><strong>Attention Maps:</strong></span>
                            <span>${(attentionMemory / 1024 / 1024).toFixed(1)} MB</span>
                        </div>
                        <div class="memory-row">
                            <span><strong>Layer Activations:</strong></span>
                            <span>${(activationMemory / 1024 / 1024).toFixed(1)} MB</span>
                        </div>
                        <div class="memory-row">
                            <span><strong>Total Memory (per sample):</strong></span>
                            <span>${(totalMemory / 1024 / 1024).toFixed(1)} MB</span>
                        </div>
                    </div>
                    
                    <div class="complexity-analysis">
                        <strong>‚ö° Attention Complexity Breakdown:</strong><br><br>
                        ‚Ä¢ <strong>Sequence Length:</strong> N = ${seqLen}<br>
                        ‚Ä¢ <strong>Attention Matrix Size:</strong> N¬≤ = ${(seqLen * seqLen).toLocaleString()}<br>
                        ‚Ä¢ <strong>Memory per Head:</strong> ${(seqLen * seqLen * 2 / 1024).toFixed(0)} KB<br>
                        ‚Ä¢ <strong>Total Attention Memory:</strong> ${(seqLen * seqLen * 12 * 2 / 1024 / 1024).toFixed(1)} MB<br><br>
                        <strong>Scaling Factor vs 32√ó32 patches:</strong> ${((seqLen / ((imageRes/32)**2 + 1))**2).toFixed(1)}√ó
                    </div>
                `;
            } else if (analysisType === 'flops') {
                const patchEmbedFlops = numPatches * (patchSize * patchSize * 3) * embedDim;
                const attentionFlops = 12 * (3 * seqLen * embedDim * embedDim + seqLen * seqLen * embedDim);
                const mlpFlops = 12 * 2 * seqLen * embedDim * (embedDim * 4);
                const totalFlops = patchEmbedFlops + attentionFlops + mlpFlops;
                
                html += `
                    <table>
                        <tr><th>Component</th><th>FLOPs</th><th>Percentage</th><th>Per Token</th></tr>
                        <tr>
                            <td><strong>Patch Embedding</strong></td>
                            <td>${(patchEmbedFlops / 1e9).toFixed(2)}G</td>
                            <td>${(patchEmbedFlops / totalFlops * 100).toFixed(1)}%</td>
                            <td>${(patchEmbedFlops / numPatches / 1e6).toFixed(1)}M</td>
                        </tr>
                        <tr>
                            <td><strong>Attention Layers</strong></td>
                            <td class="moderate">${(attentionFlops / 1e9).toFixed(2)}G</td>
                            <td>${(attentionFlops / totalFlops * 100).toFixed(1)}%</td>
                            <td>${(attentionFlops / seqLen / 1e6).toFixed(1)}M</td>
                        </tr>
                        <tr>
                            <td><strong>MLP Layers</strong></td>
                            <td class="poor">${(mlpFlops / 1e9).toFixed(2)}G</td>
                            <td>${(mlpFlops / totalFlops * 100).toFixed(1)}%</td>
                            <td>${(mlpFlops / seqLen / 1e6).toFixed(1)}M</td>
                        </tr>
                        <tr>
                            <td><strong>Total FLOPs</strong></td>
                            <td class="optimal">${(totalFlops / 1e9).toFixed(2)}G</td>
                            <td>100%</td>
                            <td>${(totalFlops / seqLen / 1e6).toFixed(1)}M</td>
                        </tr>
                    </table>
                    
                    <div class="info">
                        <strong>üí° FLOP Insights:</strong><br>
                        ‚Ä¢ Total compute: ${(totalFlops / 1e12).toFixed(3)} TFLOPs per forward pass<br>
                        ‚Ä¢ Attention dominance: ${attentionFlops > mlpFlops ? 'No' : 'Yes'} (MLP typically dominates until very high resolution)<br>
                        ‚Ä¢ Scaling vs 16√ó16: ${(totalFlops / (numPatches * 0.8e9)).toFixed(1)}√ó (approximate)<br>
                        ‚Ä¢ GPU utilization: ${totalFlops < 1e11 ? 'Light' : totalFlops < 5e11 ? 'Moderate' : 'Heavy'} computational load
                    </div>
                `;
            } else { // comparison
                const sizes = [8, 16, 24, 32];
                html += `
                    <div class="scaling-grid">
                        ${sizes.map(size => {
                            const patches = (imageRes / size) ** 2;
                            const tokens = patches + 1;
                            const attentionOps = tokens * tokens * 12;
                            const relativeSpeed = (seqLen * seqLen) / (tokens * tokens);
                            
                            return `
                                <div class="scaling-card ${size === patchSize ? 'optimal' : ''}">
                                    <div class="scaling-label">${size}√ó${size} Patches</div>
                                    <div class="scaling-metric">${tokens}</div>
                                    <div class="scaling-description">
                                        ${Math.round(patches)} patches<br>
                                        ${relativeSpeed.toFixed(1)}√ó speed vs current<br>
                                        ${(attentionOps / 1e6).toFixed(1)}M attention ops
                                    </div>
                                </div>
                            `;
                        }).join('')}
                    </div>
                    
                    <div class="warning">
                        <strong>‚ö†Ô∏è Patch Size Trade-offs:</strong><br>
                        ‚Ä¢ <strong>8√ó8:</strong> Maximum detail, but ${((imageRes/8)**2 / (imageRes/16)**2).toFixed(0)}√ó more attention memory<br>
                        ‚Ä¢ <strong>16√ó16:</strong> Sweet spot for most applications<br>
                        ‚Ä¢ <strong>24√ó24:</strong> Good balance for high-resolution images<br>
                        ‚Ä¢ <strong>32√ó32:</strong> Most efficient, but may lose important spatial details
                    </div>
                `;
            }
            
            html += '</div>';
            document.getElementById('patchAnalysisResults').innerHTML = html;
        }

        function analyzeLinearProjection() {
            const patchSize = parseInt(document.getElementById('projPatchSize').value);
            const embedDim = parseInt(document.getElementById('projEmbedDim').value);
            const channels = parseInt(document.getElementById('projChannels').value);
            
            const inputDim = patchSize * patchSize * channels;
            const projectionParams = inputDim * embedDim + embedDim; // weights + bias
            const projectionMemory = projectionParams * 2; // FP16 bytes
            
            const html = `
                <div class="step">
                    <h4>üîÑ Linear Projection Analysis</h4>
                    
                    <div class="embedding-viz">
                        <div class="embedding-stage">
                            <div class="stage-title">Flattened Patch</div>
                            <div class="stage-content">${inputDim}D</div>
                            <div class="stage-description">${patchSize}¬≤√ó${channels} channels</div>
                        </div>
                        <div class="flow-arrow">√ó</div>
                        <div class="embedding-stage">
                            <div class="stage-title">Weight Matrix</div>
                            <div class="stage-content">${inputDim}√ó${embedDim}</div>
                            <div class="stage-description">${(projectionParams/1e6).toFixed(2)}M parameters</div>
                        </div>
                        <div class="flow-arrow">=</div>
                        <div class="embedding-stage">
                            <div class="stage-title">Embedding</div>
                            <div class="stage-content">${embedDim}D</div>
                            <div class="stage-description">Learned representation</div>
                        </div>
                    </div>
                    
                    <table>
                        <tr><th>Component</th><th>Dimensions</th><th>Parameters</th><th>Memory (FP16)</th></tr>
                        <tr>
                            <td><strong>Weight Matrix</strong></td>
                            <td>${inputDim} ‚Üí ${embedDim}</td>
                            <td class="moderate">${(inputDim * embedDim / 1e6).toFixed(2)}M</td>
                            <td>${(inputDim * embedDim * 2 / 1024 / 1024).toFixed(1)} MB</td>
                        </tr>
                        <tr>
                            <td><strong>Bias Vector</strong></td>
                            <td>${embedDim}</td>
                            <td>${(embedDim / 1e3).toFixed(1)}K</td>
                            <td>${(embedDim * 2 / 1024).toFixed(1)} KB</td>
                        </tr>
                        <tr>
                            <td><strong>Total Projection</strong></td>
                            <td>-</td>
                            <td class="optimal">${(projectionParams / 1e6).toFixed(2)}M</td>
                            <td>${(projectionMemory / 1024 / 1024).toFixed(1)} MB</td>
                        </tr>
                    </table>
                    
                    <div class="parameter-box">
                        <strong>Mathematical Properties:</strong><br>
                        ‚Ä¢ <strong>Compression Ratio:</strong> ${(inputDim / embedDim).toFixed(1)}:1 ${inputDim > embedDim ? '(Dimensionality reduction)' : '(Dimensionality expansion)'}<br>
                        ‚Ä¢ <strong>Information Bottleneck:</strong> ${inputDim > embedDim ? 'Yes - must learn to compress spatial information' : 'No - expansion allows richer representations'}<br>
                        ‚Ä¢ <strong>Parameter Efficiency:</strong> ${(projectionParams / inputDim).toFixed(1)} params per input dimension<br>
                        ‚Ä¢ <strong>Initialization Scale:</strong> œÉ = ‚àö(2/(${inputDim} + ${embedDim})) = ${Math.sqrt(2/(inputDim + embedDim)).toFixed(4)}
                    </div>
                    
                    <div class="code-block">
<strong>Implementation Note:</strong>

# Standard linear projection
projection = nn.Linear(${inputDim}, ${embedDim})

# Equivalent convolutional implementation
projection = nn.Conv2d(
    in_channels=${channels}, 
    out_channels=${embedDim},
    kernel_size=${patchSize}, 
    stride=${patchSize}
)

# Both approaches are mathematically equivalent
# Conv2d is often faster due to optimized CUDA kernels
                    </div>
                    
                    <div class="${inputDim > embedDim * 2 ? 'warning' : inputDim < embedDim / 2 ? 'info' : 'success'}">
                        <strong>${inputDim > embedDim * 2 ? '‚ö†Ô∏è High Compression' : inputDim < embedDim / 2 ? 'üí° Expansion Mode' : '‚úÖ Balanced Projection'}:</strong><br>
                        ${inputDim > embedDim * 2 ? 
                          `Severe information bottleneck - may lose spatial details. Consider larger embedding dimension or smaller patches.` :
                          inputDim < embedDim / 2 ?
                          `Embedding dimension much larger than input - allows rich representations but may be parameter inefficient.` :
                          `Good balance between input and embedding dimensions - preserves information while enabling efficient processing.`
                        }
                    </div>
                </div>
            `;
            
            document.getElementById('projectionResults').innerHTML = html;
        }

        function visualizePositionalEncoding() {
            const gridSize = parseInt(document.getElementById('posGridSize').value);
            const encodingType = document.getElementById('posEncodingType').value;
            const visualization = document.getElementById('posVisualization').value;
            
            const totalPositions = gridSize * gridSize + 1; // +1 for CLS
            
            let vizHtml = `<div class="position-encoding-viz" style="grid-template-columns: repeat(${gridSize}, 1fr);">`;
            
            // Generate all positions including CLS
            for (let pos = 0; pos < totalPositions; pos++) {
                let value, color, content;
                
                if (pos === 0) {
                    // CLS token
                    content = 'CLS';
                    color = '#dc3545';
                } else {
                    // Regular patch positions
                    const patchIndex = pos - 1;
                    const row = Math.floor(patchIndex / gridSize);
                    const col = patchIndex % gridSize;
                    
                    if (visualization === 'position_id') {
                        value = pos;
                        content = pos;
                        color = `hsl(${(pos / totalPositions) * 240}, 70%, 50%)`;
                    } else if (visualization === 'similarity') {
                        // Simulate similarity to center position
                        const centerRow = (gridSize - 1) / 2;
                        const centerCol = (gridSize - 1) / 2;
                        const distance = Math.sqrt((row - centerRow)**2 + (col - centerCol)**2);
                        value = Math.max(0, 1 - (distance / (gridSize * 0.7)));
                        content = Math.round(value * 9);
                        color = `rgba(40, 167, 69, ${Math.max(0.2, value)})`;
                    } else { // distance
                        // Distance-based encoding
                        const distance = Math.sqrt(row**2 + col**2);
                        value = distance / Math.sqrt(2 * (gridSize-1)**2);
                        content = Math.round(value * 9);
                        color = `hsl(${value * 60}, 70%, 50%)`;
                    }
                }
                
                vizHtml += `<div class="pos-cell" style="background: ${color};">${content}</div>`;
            }
            
            vizHtml += '</div>';
            
            const analysisHtml = `
                <div class="step">
                    <h4>üìç Positional Encoding Analysis</h4>
                    
                    <div class="parameter-box">
                        <strong>Configuration:</strong><br>
                        ‚Ä¢ <strong>Encoding Type:</strong> ${encodingType.charAt(0).toUpperCase() + encodingType.slice(1)}<br>
                        ‚Ä¢ <strong>Grid Size:</strong> ${gridSize}√ó${gridSize}<br>
                        ‚Ä¢ <strong>Total Positions:</strong> ${totalPositions} (including CLS)<br>
                        ‚Ä¢ <strong>Parameters:</strong> ${encodingType === 'learnable' ? `${totalPositions}√óD learnable` : encodingType.includes('sinusoidal') ? '0 (fixed)' : 'Variable'}
                    </div>
                    
                    <div class="comparison-table">
                        <table>
                            <tr>
                                <th>Property</th>
                                <th>Learnable</th>
                                <th>Sinusoidal</th>
                                <th>2D Sinusoidal</th>
                                <th>Relative</th>
                            </tr>
                            <tr>
                                <td><strong>Parameters</strong></td>
                                <td class="moderate">${totalPositions}√óD</td>
                                <td class="optimal">0</td>
                                <td class="optimal">0</td>
                                <td class="poor">2N√óD</td>
                            </tr>
                            <tr>
                                <td><strong>Flexibility</strong></td>
                                <td class="optimal">High</td>
                                <td class="poor">Low</td>
                                <td class="moderate">Medium</td>
                                <td class="optimal">High</td>
                            </tr>
                            <tr>
                                <td><strong>Resolution Transfer</strong></td>
                                <td class="poor">Poor</td>
                                <td class="moderate">Good</td>
                                <td class="optimal">Excellent</td>
                                <td class="optimal">Excellent</td>
                            </tr>
                            <tr>
                                <td><strong>2D Awareness</strong></td>
                                <td class="moderate">Learned</td>
                                <td class="poor">None</td>
                                <td class="optimal">Native</td>
                                <td class="optimal">Native</td>
                            </tr>
                        </table>
                    </div>
                    
                    <div class="${encodingType === 'learnable' ? 'success' : encodingType.includes('sinusoidal') ? 'info' : 'warning'}">
                        <strong>${encodingType === 'learnable' ? '‚úÖ Standard Choice' : encodingType.includes('sinusoidal') ? 'üí° Research Alternative' : 'üî¨ Advanced Technique'}:</strong><br>
                        ${encodingType === 'learnable' ? 
                            `Most common in production ViTs. Each position learns a unique ${Math.round(768)} (or D) dimensional embedding. Works well for fixed resolution training but requires interpolation for different input sizes.` :
                            encodingType === 'sinusoidal' ?
                            `Fixed mathematical encoding using sine/cosine functions. No parameters but treats image as 1D sequence, losing 2D spatial structure.` :
                            encodingType === '2d_sinusoidal' ?
                            `Separate sine/cosine encoding for row and column positions. Preserves 2D structure and works for any resolution, but may underperform learnable on fixed-size tasks.` :
                            `Relative position encoding focuses on relationships between positions rather than absolute locations. Better for variable sizes but significantly more complex to implement.`
                        }
                    </div>
                </div>
            `;
            
            document.getElementById('positionalEncodingViz').innerHTML = vizHtml;
            document.getElementById('positionalEncodingAnalysis').innerHTML = analysisHtml;
        }

        function simulateResolutionTransfer() {
            const trainRes = parseInt(document.getElementById('trainRes').value);
            const targetRes = parseInt(document.getElementById('targetRes').value);
            const interpMethod = document.getElementById('interpMethod').value;
            
            const patchSize = 16; // Standard
            const trainPatches = (trainRes / patchSize) ** 2;
            const targetPatches = (targetRes / patchSize) ** 2;
            const trainSeqLen = trainPatches + 1;
            const targetSeqLen = targetPatches + 1;
            
            const scalingFactor = targetRes / trainRes;
            const interpolationQuality = Math.exp(-Math.abs(Math.log(scalingFactor)));
            
            const html = `
                <div class="step">
                    <h4>üîÑ Resolution Transfer Analysis</h4>
                    
                    <div class="embedding-viz">
                        <div class="embedding-stage">
                            <div class="stage-title">Training</div>
                            <div class="stage-content">${trainRes}√ó${trainRes}</div>
                            <div class="stage-description">${trainSeqLen} positions</div>
                        </div>
                        <div class="flow-arrow">‚Üí</div>
                        <div class="embedding-stage">
                            <div class="stage-title">Interpolation</div>
                            <div class="stage-content">${interpMethod}</div>
                            <div class="stage-description">${scalingFactor.toFixed(1)}√ó scaling</div>
                        </div>
                        <div class="flow-arrow">‚Üí</div>
                        <div class="embedding-stage">
                            <div class="stage-title">Target</div>
                            <div class="stage-content">${targetRes}√ó${targetRes}</div>
                            <div class="stage-description">${targetSeqLen} positions</div>
                        </div>
                    </div>
                    
                    <table>
                        <tr><th>Aspect</th><th>Training</th><th>Target</th><th>Change Factor</th></tr>
                        <tr>
                            <td><strong>Image Resolution</strong></td>
                            <td>${trainRes}√ó${trainRes}</td>
                            <td>${targetRes}√ó${targetRes}</td>
                            <td>${scalingFactor.toFixed(1)}√ó linear scale</td>
                        </tr>
                        <tr>
                            <td><strong>Number of Patches</strong></td>
                            <td>${trainPatches}</td>
                            <td>${targetPatches}</td>
                            <td>${(targetPatches/trainPatches).toFixed(1)}√ó patches</td>
                        </tr>
                        <tr>
                            <td><strong>Sequence Length</strong></td>
                            <td>${trainSeqLen}</td>
                            <td class="${targetSeqLen > trainSeqLen * 2 ? 'poor' : targetSeqLen > trainSeqLen * 1.5 ? 'moderate' : 'optimal'}">${targetSeqLen}</td>
                            <td>${(targetSeqLen/trainSeqLen).toFixed(1)}√ó sequence length</td>
                        </tr>
                        <tr>
                            <td><strong>Attention Memory</strong></td>
                            <td>${(trainSeqLen**2 * 12 * 2 / 1024 / 1024).toFixed(1)} MB</td>
                            <td class="${targetSeqLen**2 > trainSeqLen**2 * 4 ? 'poor' : targetSeqLen**2 > trainSeqLen**2 * 2 ? 'moderate' : 'optimal'}">${(targetSeqLen**2 * 12 * 2 / 1024 / 1024).toFixed(1)} MB</td>
                            <td>${(targetSeqLen**2/trainSeqLen**2).toFixed(1)}√ó attention memory</td>
                        </tr>
                    </table>
                    
                    <div class="parameter-box">
                        <strong>Interpolation Process (${interpMethod}):</strong><br><br>
                        
                        <strong>Step 1:</strong> Reshape training positions to 2D grid<br>
                        E_pos_train: [${trainSeqLen}, D] ‚Üí [‚àö${trainPatches}, ‚àö${trainPatches}, D]<br><br>
                        
                        <strong>Step 2:</strong> ${interpMethod} interpolation to target size<br>
                        [‚àö${trainPatches}, ‚àö${trainPatches}, D] ‚Üí [‚àö${targetPatches}, ‚àö${targetPatches}, D]<br><br>
                        
                        <strong>Step 3:</strong> Reshape back to sequence<br>
                        [‚àö${targetPatches}, ‚àö${targetPatches}, D] ‚Üí [${targetSeqLen}, D]<br><br>
                        
                        <strong>Quality Score:</strong> ${(interpolationQuality * 100).toFixed(1)}% (${interpolationQuality > 0.8 ? 'Excellent' : interpolationQuality > 0.6 ? 'Good' : interpolationQuality > 0.4 ? 'Fair' : 'Poor'})
                    </div>
                    
                    <div class="${scalingFactor < 1.5 && scalingFactor > 0.7 ? 'success' : scalingFactor < 2.5 && scalingFactor > 0.4 ? 'warning' : 'danger'}">
                        <strong>${scalingFactor < 1.5 && scalingFactor > 0.7 ? '‚úÖ Good Transfer' : scalingFactor < 2.5 && scalingFactor > 0.4 ? '‚ö†Ô∏è Moderate Transfer' : 'üö® Challenging Transfer'}:</strong><br>
                        ${scalingFactor < 1.5 && scalingFactor > 0.7 ? 
                          `Resolution change is moderate - interpolation should work well with minimal performance degradation.` :
                          scalingFactor < 2.5 && scalingFactor > 0.4 ?
                          `Significant resolution change - expect some performance drop. Consider fine-tuning at target resolution for best results.` :
                          `Extreme resolution change - interpolation quality will be poor. Strongly recommend retraining or using multi-scale training approach.`
                        }<br><br>
                        
                        <strong>Recommendations:</strong><br>
                        ${scalingFactor < 1.5 && scalingFactor > 0.7 ? 
                          `‚Ä¢ Direct interpolation should work well<br>‚Ä¢ Monitor for small performance drops<br>‚Ä¢ Consider brief fine-tuning if critical` :
                          scalingFactor < 2.5 && scalingFactor > 0.4 ?
                          `‚Ä¢ Use bicubic interpolation for best quality<br>‚Ä¢ Fine-tune for 1-5% of original training<br>‚Ä¢ Consider gradual resolution adaptation` :
                          `‚Ä¢ Retrain with multi-scale data if possible<br>‚Ä¢ Use hierarchical patch embedding<br>‚Ä¢ Consider different patch sizes for target resolution`
                        }
                    </div>
                </div>
            `;
            
            document.getElementById('resolutionTransferResults').innerHTML = html;
        }

        function calculateProductionMemory() {
            const imageRes = parseInt(document.getElementById('memImageRes').value);
            const patchSize = parseInt(document.getElementById('memPatchSize').value);
            const batchSize = parseInt(document.getElementById('memBatchSize').value);
            const modelSize = document.getElementById('memModelSize').value;
            const precision = document.getElementById('memPrecision').value;
            
            const model = modelSpecs[modelSize];
            const bytesPerElement = precisionBytes[precision];
            
            const numPatches = (imageRes / patchSize) ** 2;
            const seqLen = numPatches + 1;
            
            // Memory components (in bytes)
            const inputImages = batchSize * imageRes * imageRes * 3 * bytesPerElement;
            const patchEmbeddings = batchSize * seqLen * model.dim * bytesPerElement;
            const attentionMaps = batchSize * model.layers * model.heads * seqLen * seqLen * bytesPerElement;
            const layerActivations = batchSize * model.layers * seqLen * model.dim * 4 * bytesPerElement; // 4x for intermediate states
            const modelParameters = (model.dim * model.dim * 4 * model.layers + // attention weights
                                   model.dim * model.dim * 8 * model.layers + // MLP weights  
                                   patchSize * patchSize * 3 * model.dim) * bytesPerElement; // patch embedding
            
            const totalMemory = inputImages + patchEmbeddings + attentionMaps + layerActivations + modelParameters;
            
            const html = `
                <div class="step">
                    <h4>üíæ Production Memory Analysis</h4>
                    
                    <div class="parameter-box">
                        <strong>Configuration:</strong><br>
                        ‚Ä¢ <strong>Model:</strong> ${modelSize.toUpperCase()} (${model.dim}D, ${model.layers}L, ${model.heads}H)<br>
                        ‚Ä¢ <strong>Input:</strong> ${batchSize} √ó ${imageRes}√ó${imageRes}, ${patchSize}√ó${patchSize} patches<br>
                        ‚Ä¢ <strong>Sequence Length:</strong> ${seqLen} tokens<br>
                        ‚Ä¢ <strong>Precision:</strong> ${precision.toUpperCase()} (${bytesPerElement} bytes/element)
                    </div>
                    
                    <div class="memory-breakdown">
                        <div class="memory-row">
                            <span><strong>Input Images:</strong></span>
                            <span>${(inputImages / 1024 / 1024).toFixed(0)} MB</span>
                        </div>
                        <div class="memory-row">
                            <span><strong>Model Parameters:</strong></span>
                            <span>${(modelParameters / 1024 / 1024).toFixed(0)} MB</span>
                        </div>
                        <div class="memory-row">
                            <span><strong>Patch Embeddings:</strong></span>
                            <span>${(patchEmbeddings / 1024 / 1024).toFixed(0)} MB</span>
                        </div>
                        <div class="memory-row">
                            <span><strong>Attention Maps:</strong></span>
                            <span class="${attentionMaps > totalMemory * 0.3 ? 'poor' : 'moderate'}">${(attentionMaps / 1024 / 1024).toFixed(0)} MB</span>
                        </div>
                        <div class="memory-row">
                            <span><strong>Layer Activations:</strong></span>
                            <span>${(layerActivations / 1024 / 1024).toFixed(0)} MB</span>
                        </div>
                        <div class="memory-row">
                            <span><strong>Total GPU Memory:</strong></span>
                            <span>${(totalMemory / 1024 / 1024 / 1024).toFixed(1)} GB</span>
                        </div>
                    </div>
                    
                    <div class="progress-bar">
                        <div class="progress-fill" style="width: ${Math.min(100, totalMemory / 1024 / 1024 / 1024 / 80 * 100)}%">
                            ${(totalMemory / 1024 / 1024 / 1024).toFixed(1)} GB / 80GB (A100)
                        </div>
                    </div>
                    
                    <div class="${totalMemory / 1024 / 1024 / 1024 < 12 ? 'success' : totalMemory / 1024 / 1024 / 1024 < 24 ? 'warning' : totalMemory / 1024 / 1024 / 1024 < 80 ? 'danger' : 'poor'}">
                        <strong>Hardware Assessment:</strong><br><br>
                        
                        <strong>Recommended GPU:</strong><br>
                        ${totalMemory / 1024 / 1024 / 1024 < 8 ? '‚Ä¢ RTX 3080/4070 (8-12GB) - Entry level' :
                          totalMemory / 1024 / 1024 / 1024 < 16 ? '‚Ä¢ RTX 3090/4080 (16GB) - Consumer high-end' :
                          totalMemory / 1024 / 1024 / 1024 < 24 ? '‚Ä¢ RTX 3090/4090 (24GB) - Prosumer' :
                          totalMemory / 1024 / 1024 / 1024 < 40 ? '‚Ä¢ A100 (40GB) - Data center' :
                          totalMemory / 1024 / 1024 / 1024 < 80 ? '‚Ä¢ A100 (80GB) - High-end data center' :
                          '‚Ä¢ Multi-GPU setup required'
                        }<br><br>
                        
                        <strong>Optimization Strategies:</strong><br>
                        ${totalMemory / 1024 / 1024 / 1024 > 24 ? 
                          `‚Ä¢ <strong>Reduce batch size:</strong> Try batch size ${Math.max(1, Math.floor(batchSize * 24 / (totalMemory / 1024 / 1024 / 1024)))}<br>
                           ‚Ä¢ <strong>Gradient checkpointing:</strong> Trade 30% speed for 50% memory<br>
                           ‚Ä¢ <strong>Mixed precision:</strong> Use AMP for automatic FP16/FP32<br>
                           ‚Ä¢ <strong>Patch size increase:</strong> ${patchSize}√ó${patchSize} ‚Üí ${patchSize + 4}√ó${patchSize + 4} saves ${(1 - (patchSize/(patchSize+4))**4).toFixed(0)}% memory` :
                          `‚Ä¢ <strong>Current config feasible</strong> on recommended hardware<br>
                           ‚Ä¢ <strong>Consider larger batch:</strong> Try batch size ${batchSize + 4} for better utilization<br>
                           ‚Ä¢ <strong>Enable memory optimization:</strong> Gradient checkpointing for safety margin`
                        }
                    </div>
                    
                    <div class="complexity-analysis">
                        <strong>‚ö° Memory Scaling Analysis:</strong><br><br>
                        
                        <strong>Attention Dominance:</strong> ${(attentionMaps / totalMemory * 100).toFixed(0)}% of total memory<br>
                        ${attentionMaps > totalMemory * 0.4 ? 
                          `Attention maps dominate - consider smaller patches or sequence length reduction techniques.` :
                          `Attention memory manageable - model parameters and activations are primary concerns.`
                        }<br><br>
                        
                        <strong>Batch Scaling:</strong> Memory scales linearly with batch size<br>
                        <strong>Resolution Scaling:</strong> Attention memory scales as O(resolution¬≤/patch¬≤)¬≤<br>
                        <strong>Model Scaling:</strong> Parameters scale as O(layers √ó dim¬≤)
                    </div>
                </div>
            `;
            
            document.getElementById('memoryCalculationResults').innerHTML = html;
        }

        function generateRecommendation() {
            const domain = document.getElementById('appDomain').value;
            const objectSize = document.getElementById('objectSize').value;
            const hardware = document.getElementById('hardwareConstraint').value;
            const priority = document.getElementById('performancePriority').value;
            
            // Decision logic
            let recommendedPatch, reasoning, alternatives, warnings;
            
            if (domain === 'medical') {
                recommendedPatch = objectSize === 'tiny' ? 4 : objectSize === 'small' ? 8 : 8;
                reasoning = "Medical imaging requires fine detail preservation for accurate diagnosis";
                alternatives = ["Hierarchical patches", "Multi-scale training", "Overlapping patches"];
                warnings = ["Very high memory requirements", "Need large datasets", "Consider domain-specific architectures"];
            } else if (domain === 'satellite') {
                recommendedPatch = objectSize === 'huge' ? 32 : objectSize === 'large' ? 24 : 16;
                reasoning = "Large-scale patterns in satellite imagery benefit from bigger patches";
                alternatives = ["Adaptive patch sizing", "Multi-resolution input", "Pyramid attention"];
                warnings = ["May miss small features", "Consider object detection needs"];
            } else if (domain === 'mobile') {
                recommendedPatch = hardware === 'mobile' ? 32 : 24;
                reasoning = "Mobile deployment requires computational efficiency over fine details";
                alternatives = ["Model distillation", "Quantization", "Efficient architectures (MobileViT)"];
                warnings = ["Significant accuracy trade-offs", "May not work for detail-critical tasks"];
            } else {
                // General recommendations based on object size and constraints
                if (objectSize === 'tiny') recommendedPatch = hardware === 'consumer' ? 8 : 4;
                else if (objectSize === 'small') recommendedPatch = hardware === 'consumer' ? 12 : 8;
                else if (objectSize === 'medium') recommendedPatch = 16;
                else if (objectSize === 'large') recommendedPatch = priority === 'speed' ? 24 : 20;
                else recommendedPatch = priority === 'accuracy' ? 24 : 32;
                
                reasoning = `Balanced choice considering ${objectSize} object size and ${hardware || 'general'} hardware constraints`;
                alternatives = ["Standard ViT with interpolation", "Multi-scale training", "Progressive resizing"];
                warnings = hardware === 'consumer' ? ["Memory constraints may limit batch size", "Consider gradient checkpointing"] : ["Monitor training stability", "Validate on target hardware"];
            }
            
            // Adjust for hardware constraints
            if (hardware === 'mobile' && recommendedPatch < 24) {
                recommendedPatch = Math.max(24, recommendedPatch);
                warnings.push("Increased patch size for mobile deployment");
            } else if (hardware === 'consumer' && recommendedPatch < 12) {
                warnings.push("Small patch size will require high-end consumer GPU");
            }
            
            const html = `
                <div class="step">
                    <h4>üéØ Personalized Recommendation</h4>
                    
                    <div class="embedding-viz">
                        <div class="embedding-stage">
                            <div class="stage-title">Your Application</div>
                            <div class="stage-content">${domain.charAt(0).toUpperCase() + domain.slice(1)}</div>
                            <div class="stage-description">${objectSize} objects<br>${hardware || 'flexible'} hardware</div>
                        </div>
                        <div class="flow-arrow">‚Üí</div>
                        <div class="embedding-stage optimal">
                            <div class="stage-title">Recommended</div>
                            <div class="stage-content">${recommendedPatch}√ó${recommendedPatch}</div>
                            <div class="stage-description">Optimal patch size</div>
                        </div>
                    </div>
                    
                    <div class="parameter-box">
                        <strong>Recommendation Rationale:</strong><br>
                        ${reasoning}<br><br>
                        
                        <strong>Expected Performance:</strong><br>
                        ‚Ä¢ <strong>Memory Usage:</strong> ${recommendedPatch <= 8 ? 'High' : recommendedPatch <= 16 ? 'Moderate' : 'Low'}<br>
                        ‚Ä¢ <strong>Detail Preservation:</strong> ${recommendedPatch <= 8 ? 'Excellent' : recommendedPatch <= 16 ? 'Good' : 'Fair'}<br>
                        ‚Ä¢ <strong>Training Speed:</strong> ${recommendedPatch <= 8 ? 'Slow' : recommendedPatch <= 16 ? 'Moderate' : 'Fast'}<br>
                        ‚Ä¢ <strong>Inference Speed:</strong> ${recommendedPatch <= 8 ? 'Slow' : recommendedPatch <= 16 ? 'Good' : 'Excellent'}
                    </div>
                    
                    <div class="success">
                        <strong>‚úÖ Implementation Strategy:</strong><br><br>
                        
                        <strong>Phase 1 - Baseline:</strong><br>
                        ‚Ä¢ Start with ${recommendedPatch}√ó${recommendedPatch} patches<br>
                        ‚Ä¢ Use standard learnable positional encoding<br>
                        ‚Ä¢ Train on your target resolution<br><br>
                        
                        <strong>Phase 2 - Optimization:</strong><br>
                        ${alternatives.map(alt => `‚Ä¢ Consider ${alt} if baseline insufficient`).join('<br>')}<br><br>
                        
                        <strong>Phase 3 - Production:</strong><br>
                        ‚Ä¢ Profile memory usage on target hardware<br>
                        ‚Ä¢ Optimize batch size and precision<br>
                        ‚Ä¢ Consider deployment-specific optimizations
                    </div>
                    
                    ${warnings.length > 0 ? `
                        <div class="warning">
                            <strong>‚ö†Ô∏è Important Considerations:</strong><br>
                            ${warnings.map(warning => `‚Ä¢ ${warning}`).join('<br>')}
                        </div>
                    ` : ''}
                    
                    <div class="comparison-table">
                        <h5>Alternative Configurations:</h5>
                        <table>
                            <tr>
                                <th>Patch Size</th>
                                <th>Use Case</th>
                                <th>Memory</th>
                                <th>Accuracy</th>
                                <th>Speed</th>
                            </tr>
                            ${[recommendedPatch - 8, recommendedPatch, recommendedPatch + 8].filter(p => p > 0 && p <= 32).map(patch => `
                                <tr class="${patch === recommendedPatch ? 'optimal' : ''}">
                                    <td><strong>${patch}√ó${patch}</strong></td>
                                    <td>${patch <= 8 ? 'Fine details' : patch <= 16 ? 'Balanced' : 'Efficiency'}</td>
                                    <td class="${patch <= 8 ? 'poor' : patch <= 16 ? 'moderate' : 'optimal'}">${patch <= 8 ? 'High' : patch <= 16 ? 'Med' : 'Low'}</td>
                                    <td class="${patch <= 8 ? 'optimal' : patch <= 16 ? 'moderate' : 'poor'}">${patch <= 8 ? 'High' : patch <= 16 ? 'Med' : 'Fair'}</td>
                                    <td class="${patch <= 8 ? 'poor' : patch <= 16 ? 'moderate' : 'optimal'}">${patch <= 8 ? 'Slow' : patch <= 16 ? 'Med' : 'Fast'}</td>
                                </tr>
                            `).join('')}
                        </table>
                    </div>
                </div>
            `;
            
            document.getElementById('recommendationResults').innerHTML = html;
        }

        // Event listeners and initialization
        document.addEventListener('DOMContentLoaded', function() {
            // Initialize slider updates
            const sliderIds = [
                'imageRes', 'patchSize', 'projPatchSize', 'posGridSize',
                'memImageRes', 'memPatchSize', 'memBatchSize'
            ];
            
            sliderIds.forEach(id => {
                const element = document.getElementById(id);
                if (element) {
                    element.addEventListener('input', updateSliderValues);
                }
            });
            
            // Initialize with default values
            updateSliderValues();
            
            // Run initial calculations
            setTimeout(() => {
                analyzePatchImpact();
                analyzeLinearProjection();
                visualizePositionalEncoding();
                simulateResolutionTransfer();
                calculateProductionMemory();
                generateRecommendation();
            }, 100);
        });
    </script>
</body>
</html>
